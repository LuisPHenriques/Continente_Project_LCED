{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "171de7d2",
   "metadata": {},
   "source": [
    "# Data Import & Connection to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0ce1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luish\\anaconda3\\lib\\site-packages\\google\\auth\\_default.py:78: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from google.cloud import bigquery\n",
    "from itertools import product\n",
    "from functions import *\n",
    "\n",
    "# set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Set the float format to display numbers without scientific notation\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "# Set the client for future queries to BigQuery\n",
    "client = bigquery.Client(project = \"continente-lced-feup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9862be91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=nncOts8YxzC8jHgBu0YQGd2KEI4xbH&access_type=offline&code_challenge=0OHVxkxFROkqnywJ1MTdDkvwo0aWSI8CHkTaR3cswRE&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [C:\\Users\\luish\\AppData\\Roaming\\gcloud\\application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "WARNING: \n",
      "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b16e58",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "316f5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = client.query(\"\"\"\n",
    "   SELECT *\n",
    "   FROM \n",
    "       tables_raw.dim_customer \n",
    "       JOIN tables_raw.fact_transaction USING(CUSTOMER_ACCOUNT_NR_MASK)\n",
    "       JOIN tables_raw.dim_product USING(SKU)\n",
    "    WHERE \n",
    "        SUBCAT_CD_EXT IN (140304, 50401, 30301, 20201, 10301, 80103, 60102, 60401, 30401, 10101, 100102, 100204, 140204, \n",
    "        20302, 30201, 50203, 90201, 170101, 80404, 50402, 70202, 100201, 80409, 10303, 20306, 80411, 10102, 20305, 60105, 80110, \n",
    "        140301, 30202, 90202, 100101, 80105, 80104, 50202, 50303, 70204, 60306, 80403, 10302, 10201, 80405, 170304, 170303, 80406, \n",
    "        140201, 60302, 30403, 30304, 20204, 170106, 140205, 10204, 60404, 50301, 50302, 20205, 60406, 20301, 80407, 20203, 70201, 100205,\n",
    "        60106, 170302, 50201, 60301, 10205, 30203, 80401, 100202, 30302, 170111, 10202, 70203, 60303, 170109, 60403, 30402, 140302, 30208, 60307, \n",
    "        80107, 50403, 60103, 20307, 60305, 60101, 170307, 80414, 80415, 60405, 20303, 80402, 30204, 30206, 170310, 60304, 140206, 10203, 30205, 60107, \n",
    "        70206, 170108, 90203, 90204, 30207, 140303, 30303, 80408, 140202, 50304, 80101, 170313, 100203, 60402, 170305, 50305, 50404, 20202, 170110, \n",
    "        170105, 170112, 170301, 10206, 10208, 20304, 80102, 70205, 10207, 10305, 170309, 170114, 80111, 90206, 30306, 30305, 140203, 80413) \n",
    "        AND SEG_AGE_DSC = ']25;35]'\n",
    "        AND QTY >= 0\n",
    "    ORDER BY CUSTOMER_ACCOUNT_NR_MASK DESC, TIME_KEY ASC\n",
    "   \"\"\")\n",
    "\n",
    "df = query.result().to_dataframe() # Wait for the job to complete."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be7227ad",
   "metadata": {},
   "source": [
    "# Data Preparation (more to be done...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e64ae92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['LOC_BRAND_CD','PROD_DSCNT_ISSUED_AMT','NET_SLS_AMT','TRANS_DSCNT_RAT_AMT','DIRECT_DSCNT_AMT',\n",
    "                 'seg_lifestyle_dsc','SEG_AGE','SEG_AGE_DSC','seg_lifestage_dsc',\n",
    "                 'UNIT_BASE_DSC_EXT','SUBCAT_DSC_EXT','BIZ_UNIT_DSC_EXT','DEPARTMENT_DSC_EXT',\n",
    "                'PRODUCT_SHORT_DSC','BRAND_DSC','BRAND_TYPE_CD','CONVERSION_FACTOR','CAPACITY_UNIT','PRODUCT_DSC','SKU',\n",
    "                'LOCATION_CD','GROSS_SLS_AMT','CP4','CAT_DSC_EXT','PRODUCT_KEY','POS_TP_CD','PRICE_RANGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba3d06f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUSTOMER_ACCOUNT_NR_MASK         0\n",
       "GENDER                      207890\n",
       "FAMILY_MEMBERS              778011\n",
       "seg_lifestyle_cd                 0\n",
       "seg_lifestage_cd                 0\n",
       "TIME_KEY                         0\n",
       "TRANSACTION_ID_MASK              0\n",
       "QTY                              0\n",
       "UNIT_BASE_CD_EXT                 0\n",
       "SUBCAT_CD_EXT                    0\n",
       "CAT_CD_EXT                       0\n",
       "BIZ_UNIT_CD_EXT                  0\n",
       "DEPARTMENT_CD_EXT                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38d1321e",
   "metadata": {},
   "source": [
    "# Feature Engineering & ML Dataset Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3808f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'TIME_KEY' column to datetime format\n",
    "df['TIME_KEY'] = pd.to_datetime(df['TIME_KEY'], format='%Y%m%d')\n",
    "\n",
    "# create new columns for the day, week, day of the week, month, quarter, and year\n",
    "#df['DAY'] = df['TIME_KEY'].dt.day\n",
    "#df['WEEK'] = df['TIME_KEY'].dt.week\n",
    "#df['DOW'] = df['TIME_KEY'].dt.dayofweek\n",
    "df['MONTH'] = df['TIME_KEY'].dt.month\n",
    "df['QUARTER'] = df['TIME_KEY'].dt.quarter\n",
    "df['SEMESTER'] = df['MONTH'].apply(semester)\n",
    "df['YEAR'] = df['TIME_KEY'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7dd3b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe by the customer's frequency score\n",
    "df = filter_customers(df)\n",
    "# Sort the dataframe (later suffled again)\n",
    "df = df.sort_values(['TIME_KEY','TRANSACTION_ID_MASK','YEAR','MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "779ad40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Drop duplicates, keeping only the first occurrence of each customer ID\n",
    "df_first_transaction = df.drop_duplicates('CUSTOMER_ACCOUNT_NR_MASK', keep='first')\n",
    "\n",
    "# Step 3: Create a new DataFrame with customer ID and first transaction date\n",
    "df_first_transaction = df_first_transaction[['CUSTOMER_ACCOUNT_NR_MASK', 'TIME_KEY']]\n",
    "\n",
    "# Convert the 'TIME_KEY' column to datetime type\n",
    "df_first_transaction['TIME_KEY'] = pd.to_datetime(df_first_transaction['TIME_KEY'])\n",
    "\n",
    "# Extract the year and month from the 'TIME_KEY' column and format it as \"year-month\"\n",
    "df_first_transaction['TIME_KEY'] = df_first_transaction['TIME_KEY'].dt.strftime('%Y-%m')\n",
    "\n",
    "df_first_transaction = df_first_transaction.sort_values(['CUSTOMER_ACCOUNT_NR_MASK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0504cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique values of customer_id, category_id, month and year\n",
    "customer_ids = df['CUSTOMER_ACCOUNT_NR_MASK'].unique()\n",
    "category_ids = df['SUBCAT_CD_EXT'].unique()\n",
    "months = df['MONTH'].unique()\n",
    "years = df['YEAR'].unique()\n",
    "\n",
    "# create a new dataframe with all possible combinations of customer_id and category_id\n",
    "ml_dataset = pd.DataFrame(list(product(customer_ids, category_ids, months, years)), \n",
    "                                    columns=['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','MONTH','YEAR'])\n",
    "\n",
    "# add the quarter and semester columns based on the month value\n",
    "quarter_map = {1: 1, 2: 1, 3: 1, 4: 2, 5: 2, 6: 2, 7: 3, 8: 3, 9: 3, 10: 4, 11: 4, 12: 4}\n",
    "semester_map = {1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 2, 8: 2, 9: 2, 10: 2, 11: 2, 12: 2}\n",
    "\n",
    "ml_dataset['QUARTER'] = ml_dataset['MONTH'].map(quarter_map)\n",
    "ml_dataset['SEMESTER'] = ml_dataset['MONTH'].map(semester_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d930de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 'year' and 'month' columns into a single column\n",
    "ml_dataset['TIME_KEY_agg'] = ml_dataset['YEAR'].astype(str) + '-' + ml_dataset['MONTH'].astype(str)\n",
    "\n",
    "# Convert the 'TIME_KEY' column to datetime format\n",
    "ml_dataset['TIME_KEY_agg'] = pd.to_datetime(ml_dataset['TIME_KEY_agg'], format='%Y-%m')\n",
    "\n",
    "# Extract the year and month from the 'TIME_KEY' column and format it as \"year-month\"\n",
    "ml_dataset['TIME_KEY_agg'] = ml_dataset['TIME_KEY_agg'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Step 3: Merge with the aggregated dataset\n",
    "ml_dataset = pd.merge(ml_dataset, df_first_transaction, on='CUSTOMER_ACCOUNT_NR_MASK', how='left')\n",
    "\n",
    "# Step 4: Filter the aggregated dataset based on the first transaction date\n",
    "ml_dataset = ml_dataset[ml_dataset['TIME_KEY_agg'] >= ml_dataset['TIME_KEY']]\n",
    "\n",
    "ml_dataset = ml_dataset.drop(columns=['TIME_KEY_agg','TIME_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6523fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dataset = ml_dataset.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','YEAR','MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b0d0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','TIME_KEY'])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28d88ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\\nml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\\nml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\\nml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOTAL NUMBER OF ORDERS - CORRETO!\n",
    "\n",
    "df_uniques = df.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='first').reset_index()\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_30_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='30D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_90_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='90D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_180_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='180D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_360_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='360D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df = pd.merge(df, df_uniques[['TRANSACTION_ID_MASK','CUST_NUM_TRANSACTIONS_30_DAYS','CUST_NUM_TRANSACTIONS_90_DAYS','CUST_NUM_TRANSACTIONS_180_DAYS',\n",
    "                             'CUST_NUM_TRANSACTIONS_360_DAYS']], on=['TRANSACTION_ID_MASK'], how='left')\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "600002d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL QUATITY BOUGHT BY CUSTOMER - CORRETO!\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_30_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='30D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_90_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='90D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_180_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='180D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_360_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='360D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d73661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIQUE NUMBER OF SUBCATEGORIES BOUGHT - CORRETO!\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_30_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='30D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_90_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='90D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_180_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='180D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_360_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='360D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f57279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE DAYS FOR NEXT CUSTOMER'S TRANSACTION - CORRETO!\n",
    "\n",
    "df_uniques = df.copy()\n",
    "df_uniques['DAYS_FOR_NEXT_TRANSACTION'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK'])['TIME_KEY'].diff(-1).dt.days \\\n",
    "                                              .fillna(0).apply(lambda x: abs(x))\n",
    "df_uniques = df_uniques.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='last').reset_index()\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                   .rolling(window='30D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(30)\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_90_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                   .rolling(window='90D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(60)\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_180_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                    .rolling(window='180D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(180)\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_360_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                    .rolling(window='360D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(360)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "\n",
    "# Regression Feature - Average days for the next transaction in the next 30 days of a certain month, by customer\n",
    "\n",
    "ml_dataset['REG_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS'] = ml_dataset.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                    .CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS \\\n",
    "                                                                    .shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcbd0bb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.31 GiB for an array with shape (40, 22197207) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUST_NUM_SUBCAT_360_DAYS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUSTOMER_ACCOUNT_NR_MASK\u001b[39m\u001b[38;5;124m'\u001b[39m]) \\\n\u001b[0;32m     19\u001b[0m                                   \u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m360D\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIME_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m, min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mSUBCAT_CD_EXT \\\n\u001b[0;32m     20\u001b[0m                                   \u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;241m.\u001b[39mreset_index()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBCAT_CD_EXT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     21\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUST_AVG_BASKET_SIZE_360_DAYS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUST_NUM_SUBCAT_360_DAYS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUST_NUM_TRANSACTIONS_360_DAYS\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 23\u001b[0m ml_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_aggregations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m30_DAYS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCUST_AVG_BASKET_SIZE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCUST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m ml_dataset \u001b[38;5;241m=\u001b[39m create_aggregations(df, ml_dataset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m90_DAYS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUST_AVG_BASKET_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUST\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m ml_dataset \u001b[38;5;241m=\u001b[39m create_aggregations(df, ml_dataset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m180_DAYS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUST_AVG_BASKET_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUST\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Desktop\\feature engineering\\functions.py:181\u001b[0m, in \u001b[0;36mcreate_aggregations\u001b[1;34m(df_transactions, df_ml, interval, feature, f_type, avg)\u001b[0m\n\u001b[0;32m    175\u001b[0m     aggregations \u001b[38;5;241m=\u001b[39m df_transactions[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUSTOMER_ACCOUNT_NR_MASK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m, feature\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39minterval]] \\\n\u001b[0;32m    176\u001b[0m                             \u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUSTOMER_ACCOUNT_NR_MASK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m]) \\\n\u001b[0;32m    177\u001b[0m                             \u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUSTOMER_ACCOUNT_NR_MASK\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEAR\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m, feature\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39minterval: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m'\u001b[39m}) \\\n\u001b[0;32m    178\u001b[0m                             \u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# merge the aggregations dataframe with the new_df dataframe on the customer id, subcategory id, and month columns\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     df_ml \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCUSTOMER_ACCOUNT_NR_MASK\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYEAR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMONTH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m f_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBCAT\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    184\u001b[0m     aggregations \u001b[38;5;241m=\u001b[39m df_transactions[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBCAT_CD_EXT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m, feature\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39minterval]] \\\n\u001b[0;32m    185\u001b[0m                             \u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBCAT_CD_EXT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m]) \\\n\u001b[0;32m    186\u001b[0m                             \u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBCAT_CD_EXT\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEAR\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m, feature\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39minterval: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m'\u001b[39m}) \\\n\u001b[0;32m    187\u001b[0m                             \u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:122\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    107\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    108\u001b[0m         left,\n\u001b[0;32m    109\u001b[0m         right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    121\u001b[0m     )\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:725\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    722\u001b[0m lindexers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m1\u001b[39m: left_indexer} \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    723\u001b[0m rindexers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m1\u001b[39m: right_indexer} \u001b[38;5;28;01mif\u001b[39;00m right_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 725\u001b[0m result_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlindexers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrindexers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mllabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    732\u001b[0m typ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39m_constructor\n\u001b[0;32m    733\u001b[0m result \u001b[38;5;241m=\u001b[39m typ(result_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:202\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_concat_managers_axis0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m mgrs_indexers \u001b[38;5;241m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# Assertion disabled for performance\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# assert all(not x[1] for x in mgrs_indexers)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:264\u001b[0m, in \u001b[0;36m_concat_managers_axis0\u001b[1;34m(mgrs_indexers, axes, copy)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03mconcat_managers specialized to concat_axis=0, with reindexing already\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124;03mhaving been done in _maybe_reindex_columns_na_proxy.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m had_reindexers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    262\u001b[0m     i: \u001b[38;5;28mlen\u001b[39m(mgrs_indexers[i][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mgrs_indexers))\n\u001b[0;32m    263\u001b[0m }\n\u001b[1;32m--> 264\u001b[0m mgrs_indexers \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_reindex_columns_na_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m mgrs \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mgrs_indexers]\n\u001b[0;32m    268\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:306\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[1;34m(axes, mgrs_indexers)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mgr, indexers \u001b[38;5;129;01min\u001b[39;00m mgrs_indexers:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;66;03m# For axis=0 (i.e. columns) we use_na_proxy and only_slice, so this\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;66;03m#  is a cheap reindexing.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, indexer \u001b[38;5;129;01min\u001b[39;00m indexers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 306\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m            \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# only relevant for i==0\u001b[39;49;00m\n\u001b[0;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# only relevant for i==0\u001b[39;49;00m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     new_mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((mgr, {}))\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgrs_indexers\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:675\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m--> 675\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;66;03m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dups:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1685\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1686\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2084\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2082\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2084\u001b[0m     merged_blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2085\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2087\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_blocks\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2111\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2104\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   2107\u001b[0m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2108\u001b[0m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2109\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2110\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2111\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2113\u001b[0m     bvals \u001b[38;5;241m=\u001b[39m [blk\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    281\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.31 GiB for an array with shape (40, 22197207) and data type int32"
     ]
    }
   ],
   "source": [
    "# AVERAGE BASKET SIZE - CORRETO!\n",
    "\n",
    "df['CUST_NUM_SUBCAT_30_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='30D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_30_DAYS'] = df['CUST_NUM_SUBCAT_30_DAYS'] / df['CUST_NUM_TRANSACTIONS_30_DAYS']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_90_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='90D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_90_DAYS'] = df['CUST_NUM_SUBCAT_90_DAYS'] / df['CUST_NUM_TRANSACTIONS_90_DAYS']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_180_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='180D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_180_DAYS'] = df['CUST_NUM_SUBCAT_180_DAYS'] / df['CUST_NUM_TRANSACTIONS_180_DAYS']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_360_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='360D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_360_DAYS'] = df['CUST_NUM_SUBCAT_360_DAYS'] / df['CUST_NUM_TRANSACTIONS_360_DAYS']\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4087154b",
   "metadata": {},
   "source": [
    "Subcategory features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ed446ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['SUBCAT_CD_EXT','TIME_KEY'])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14aa99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS - CORRETO!\n",
    "\n",
    "df_uniques = df.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='first').reset_index()\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_30_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='30D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_90_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='90D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_180_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='180D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_360_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='360D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7328026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL QUATITY BOUGHT BY SUBCATEGORY - CORRETO!\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_30_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='30D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_90_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='90D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_180_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='180D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_360_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='360D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a3648ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIQUE NUMBER OF CUSTOMERS WHO BOUGHT FROM A SUBCATEGORY - CORRETO!\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_30_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='30D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_90_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='90D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_180_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='180D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_360_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='360D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b98bce3a",
   "metadata": {},
   "source": [
    "Customer-Subcategory features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "848079f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','TIME_KEY'])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4345f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS FOR A SUBCATEGORY BY A SPECIFIC CUSTOMER - CORRETO!\n",
    "\n",
    "df_uniques = df.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='first').reset_index()\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_30_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='30D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_90_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='90D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_180_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='180D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_360_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='360D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "875e4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL QUATITY BOUGHT BY CUSTOMER BY SUBCATEGORY - CORRETO!\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_30_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='30D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                              .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_90_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='90D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                              .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_180_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='180D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                               .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_360_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='360D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                               .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d380e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE DAYS FOR NEXT CUSTOMER'S TRANSACTION WITH A CERTAIN SUBCATEGORY - CORRETO!\n",
    "\n",
    "df_uniques = df.copy()\n",
    "df_uniques['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT'])['TIME_KEY'].diff(-1).dt.days \\\n",
    "                                              .fillna(0).apply(lambda x: abs(x))\n",
    "df_uniques = df_uniques.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='last').reset_index()\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                   .rolling(window='30D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(30)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_90_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                   .rolling(window='90D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(60)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_180_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                    .rolling(window='180D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(180)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_360_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                    .rolling(window='360D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(360)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5affcba2",
   "metadata": {},
   "source": [
    "Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3045e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = fill_missing_values(df)  # Fills the missing values of the customer column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6578e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "customer_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['GENDER']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['GENDER'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(customer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c25de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "family_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['FAMILY_MEMBERS']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['FAMILY_MEMBERS'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(family_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e904447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestyle_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['seg_lifestyle_cd']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['SEG_LIFESTYLE_CD'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(lifestyle_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22e1e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestage_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['seg_lifestage_cd']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['SEG_LIFESTAGE_CD'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(lifestage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da9c09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = client.query(\"\"\"\n",
    "   SELECT SUBCAT_CD_EXT, CAT_CD_EXT, PRICE_RANGE\n",
    "   FROM tables_raw.dim_product\n",
    "   \"\"\")\n",
    "\n",
    "products = query.result().to_dataframe() # Wait for the job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89950622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestage_dict = dict(zip(products['SUBCAT_CD_EXT'], products['CAT_CD_EXT']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['CAT_CD_EXT'] = ml_dataset['SUBCAT_CD_EXT'].map(lifestage_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffe6eeb2",
   "metadata": {},
   "source": [
    "Target features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d837c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dataset = ml_dataset.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','YEAR','MONTH'])\n",
    "ml_dataset = compute_target(ml_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85f5f290",
   "metadata": {},
   "source": [
    "# Load dataset into BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataframe\n",
    "ml_dataset = ml_dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b07ba597",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.21 GiB for an array with shape (11, 26953560) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#### SAVE DATAFRAME TO BIGQUERY ####\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mml_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtables_staging.df_models\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:2661\u001b[0m, in \u001b[0;36mClient.load_table_from_dataframe\u001b[1;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression, timeout)\u001b[0m\n\u001b[0;32m   2643\u001b[0m         columns_and_indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(\n\u001b[0;32m   2644\u001b[0m             name\n\u001b[0;32m   2645\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m _pandas_helpers\u001b[38;5;241m.\u001b[39mlist_columns_and_indexes(dataframe)\n\u001b[0;32m   2646\u001b[0m         )\n\u001b[0;32m   2647\u001b[0m         new_job_config\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2648\u001b[0m             \u001b[38;5;66;03m# Field description and policy tags are not needed to\u001b[39;00m\n\u001b[0;32m   2649\u001b[0m             \u001b[38;5;66;03m# serialize a data frame.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m columns_and_indexes\n\u001b[0;32m   2659\u001b[0m         ]\n\u001b[1;32m-> 2661\u001b[0m new_job_config\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe_to_bq_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_job_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\n\u001b[0;32m   2663\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_job_config\u001b[38;5;241m.\u001b[39mschema:\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;66;03m# the schema could not be fully detected\u001b[39;00m\n\u001b[0;32m   2667\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2668\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSchema could not be detected for all columns. Loading from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2669\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe without a schema will be deprecated in the future, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2672\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2673\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484\u001b[0m, in \u001b[0;36mdataframe_to_bq_schema\u001b[1;34m(dataframe, bq_schema)\u001b[0m\n\u001b[0;32m    482\u001b[0m bq_type \u001b[38;5;241m=\u001b[39m _PANDAS_DTYPE_TO_BQ\u001b[38;5;241m.\u001b[39mget(dtype\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bq_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     sample_data \u001b[38;5;241m=\u001b[39m _first_valid(\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[column])\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(sample_data, _BaseGeometry)\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m sample_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Paranoia\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     ):\n\u001b[0;32m    489\u001b[0m         bq_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEOGRAPHY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5787\u001b[0m, in \u001b[0;36mDataFrame.reset_index\u001b[1;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[0;32m   5785\u001b[0m     new_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   5786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 5787\u001b[0m     new_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5789\u001b[0m new_index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(new_obj))\n\u001b[0;32m   5790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6032\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   5926\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   5927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, deep: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   5928\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5929\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   5930\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6030\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[0;32m   6031\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6032\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6033\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:603\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    601\u001b[0m     new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 603\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:643\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    641\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 643\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(values, placement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr_locs, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.21 GiB for an array with shape (11, 26953560) and data type float64"
     ]
    }
   ],
   "source": [
    "#### SAVE DATAFRAME TO BIGQUERY ####\n",
    "client.load_table_from_dataframe(ml_dataset, 'tables_staging.df_models').result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
