{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "171de7d2",
   "metadata": {},
   "source": [
    "# Data Import & Connection to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0ce1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from google.cloud import bigquery\n",
    "from itertools import product\n",
    "from functions import *\n",
    "\n",
    "# set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Set the float format to display numbers without scientific notation\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "# Set the client for future queries to BigQuery\n",
    "client = bigquery.Client(project = \"continente-lced-feup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9862be91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=jdgQnx67dqpnv8yFuFT77FaW6u0q43&access_type=offline&code_challenge=koXgsOMBkEO_w6pLQs9nw3joCsQ7H_UIWYnfwRu6aTk&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [/Users/vp/.config/gcloud/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"continente-lced-feup\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b16e58",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316f5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = client.query(\"\"\"\n",
    "   SELECT *\n",
    "   FROM \n",
    "       tables_raw.dim_customer \n",
    "       JOIN tables_raw.fact_transaction USING(CUSTOMER_ACCOUNT_NR_MASK)\n",
    "       JOIN tables_raw.dim_product USING(SKU)\n",
    "    WHERE \n",
    "        SUBCAT_CD_EXT IN (140304, 50401, 30301, 20201, 10301, 80103, 60102, 60401, 30401, 10101, 100102, 100204, 140204, \n",
    "        20302, 30201, 50203, 90201, 170101, 80404, 50402, 70202, 100201, 80409, 10303, 20306, 80411, 10102, 20305, 60105, 80110, \n",
    "        140301, 30202, 90202, 100101, 80105, 80104, 50202, 50303, 70204, 60306, 80403, 10302, 10201, 80405, 170304, 170303, 80406, \n",
    "        140201, 60302, 30403, 30304, 20204, 170106, 140205, 10204, 60404, 50301, 50302, 20205, 60406, 20301, 80407, 20203, 70201, 100205,\n",
    "        60106, 170302, 50201, 60301, 10205, 30203, 80401, 100202, 30302, 170111, 10202, 70203, 60303, 170109, 60403, 30402, 140302, 30208, 60307, \n",
    "        80107, 50403, 60103, 20307, 60305, 60101, 170307, 80414, 80415, 60405, 20303, 80402, 30204, 30206, 170310, 60304, 140206, 10203, 30205, 60107, \n",
    "        70206, 170108, 90203, 90204, 30207, 140303, 30303, 80408, 140202, 50304, 80101, 170313, 100203, 60402, 170305, 50305, 50404, 20202, 170110, \n",
    "        170105, 170112, 170301, 10206, 10208, 20304, 80102, 70205, 10207, 10305, 170309, 170114, 80111, 90206, 30306, 30305, 140203, 80413) \n",
    "        AND SEG_AGE_DSC = ']25;35]'\n",
    "        AND QTY >= 0\n",
    "    ORDER BY CUSTOMER_ACCOUNT_NR_MASK DESC, TIME_KEY ASC\n",
    "   \"\"\")\n",
    "\n",
    "df = query.result().to_dataframe() # Wait for the job to complete."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be7227ad",
   "metadata": {},
   "source": [
    "# Data Preparation (more to be done...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64ae92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['LOC_BRAND_CD','PROD_DSCNT_ISSUED_AMT','NET_SLS_AMT','TRANS_DSCNT_RAT_AMT','DIRECT_DSCNT_AMT',\n",
    "                 'seg_lifestyle_dsc','SEG_AGE','SEG_AGE_DSC','seg_lifestage_dsc',\n",
    "                 'UNIT_BASE_DSC_EXT','SUBCAT_DSC_EXT','BIZ_UNIT_DSC_EXT','DEPARTMENT_DSC_EXT',\n",
    "                'PRODUCT_SHORT_DSC','BRAND_DSC','BRAND_TYPE_CD','CONVERSION_FACTOR','CAPACITY_UNIT','PRODUCT_DSC','SKU',\n",
    "                'LOCATION_CD','GROSS_SLS_AMT','CP4','CAT_DSC_EXT','PRODUCT_KEY','POS_TP_CD','PRICE_RANGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba3d06f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUSTOMER_ACCOUNT_NR_MASK         0\n",
       "GENDER                      207890\n",
       "FAMILY_MEMBERS              778011\n",
       "seg_lifestyle_cd                 0\n",
       "seg_lifestage_cd                 0\n",
       "TIME_KEY                         0\n",
       "TRANSACTION_ID_MASK              0\n",
       "QTY                              0\n",
       "UNIT_BASE_CD_EXT                 0\n",
       "SUBCAT_CD_EXT                    0\n",
       "CAT_CD_EXT                       0\n",
       "BIZ_UNIT_CD_EXT                  0\n",
       "DEPARTMENT_CD_EXT                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38d1321e",
   "metadata": {},
   "source": [
    "# Feature Engineering & ML Dataset Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3808f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'TIME_KEY' column to datetime format\n",
    "df['TIME_KEY'] = pd.to_datetime(df['TIME_KEY'], format='%Y%m%d')\n",
    "\n",
    "# create new columns for the day, week, day of the week, month, quarter, and year\n",
    "#df['DAY'] = df['TIME_KEY'].dt.day\n",
    "#df['WEEK'] = df['TIME_KEY'].dt.week\n",
    "#df['DOW'] = df['TIME_KEY'].dt.dayofweek\n",
    "df['MONTH'] = df['TIME_KEY'].dt.month\n",
    "df['QUARTER'] = df['TIME_KEY'].dt.quarter\n",
    "df['SEMESTER'] = df['MONTH'].apply(semester)\n",
    "df['YEAR'] = df['TIME_KEY'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd3b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe by the customer's frequency score\n",
    "df = filter_customers(df)\n",
    "# Sort the dataframe (later suffled again)\n",
    "df = df.sort_values(['TIME_KEY','TRANSACTION_ID_MASK','YEAR','MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "779ad40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Drop duplicates, keeping only the first occurrence of each customer ID\n",
    "df_first_transaction = df.drop_duplicates('CUSTOMER_ACCOUNT_NR_MASK', keep='first')\n",
    "\n",
    "# Step 3: Create a new DataFrame with customer ID and first transaction date\n",
    "df_first_transaction = df_first_transaction[['CUSTOMER_ACCOUNT_NR_MASK', 'TIME_KEY']]\n",
    "\n",
    "# Convert the 'TIME_KEY' column to datetime type\n",
    "df_first_transaction['TIME_KEY'] = pd.to_datetime(df_first_transaction['TIME_KEY'])\n",
    "\n",
    "# Extract the year and month from the 'TIME_KEY' column and format it as \"year-month\"\n",
    "df_first_transaction['TIME_KEY'] = df_first_transaction['TIME_KEY'].dt.strftime('%Y-%m')\n",
    "\n",
    "df_first_transaction = df_first_transaction.sort_values(['CUSTOMER_ACCOUNT_NR_MASK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd0504cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique values of customer_id, category_id, month and year\n",
    "customer_ids = df['CUSTOMER_ACCOUNT_NR_MASK'].unique()\n",
    "category_ids = df['SUBCAT_CD_EXT'].unique()\n",
    "months = df['MONTH'].unique()\n",
    "years = df['YEAR'].unique()\n",
    "\n",
    "# create a new dataframe with all possible combinations of customer_id and category_id\n",
    "ml_dataset = pd.DataFrame(list(product(customer_ids, category_ids, months, years)), \n",
    "                                    columns=['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','MONTH','YEAR'])\n",
    "\n",
    "# add the quarter and semester columns based on the month value\n",
    "quarter_map = {1: 1, 2: 1, 3: 1, 4: 2, 5: 2, 6: 2, 7: 3, 8: 3, 9: 3, 10: 4, 11: 4, 12: 4}\n",
    "semester_map = {1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 2, 8: 2, 9: 2, 10: 2, 11: 2, 12: 2}\n",
    "\n",
    "ml_dataset['QUARTER'] = ml_dataset['MONTH'].map(quarter_map)\n",
    "ml_dataset['SEMESTER'] = ml_dataset['MONTH'].map(semester_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d930de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 'year' and 'month' columns into a single column\n",
    "ml_dataset['TIME_KEY_agg'] = ml_dataset['YEAR'].astype(str) + '-' + ml_dataset['MONTH'].astype(str)\n",
    "\n",
    "# Convert the 'TIME_KEY' column to datetime format\n",
    "ml_dataset['TIME_KEY_agg'] = pd.to_datetime(ml_dataset['TIME_KEY_agg'], format='%Y-%m')\n",
    "\n",
    "# Extract the year and month from the 'TIME_KEY' column and format it as \"year-month\"\n",
    "ml_dataset['TIME_KEY_agg'] = ml_dataset['TIME_KEY_agg'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Step 3: Merge with the aggregated dataset\n",
    "ml_dataset = pd.merge(ml_dataset, df_first_transaction, on='CUSTOMER_ACCOUNT_NR_MASK', how='left')\n",
    "\n",
    "# Step 4: Filter the aggregated dataset based on the first transaction date\n",
    "ml_dataset = ml_dataset[ml_dataset['TIME_KEY_agg'] >= ml_dataset['TIME_KEY']]\n",
    "\n",
    "ml_dataset = ml_dataset.drop(columns=['TIME_KEY_agg','TIME_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6523fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dataset = ml_dataset.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','YEAR','MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b0d0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','TIME_KEY'])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d88ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS - CORRETO!\n",
    "\n",
    "df_uniques = df.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='first').reset_index()\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_30_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='30D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_90_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='90D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_180_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='180D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_360_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='360D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df = pd.merge(df, df_uniques[['TRANSACTION_ID_MASK','CUST_NUM_TRANSACTIONS_30_DAYS','CUST_NUM_TRANSACTIONS_90_DAYS','CUST_NUM_TRANSACTIONS_180_DAYS',\n",
    "                             'CUST_NUM_TRANSACTIONS_360_DAYS']], on=['TRANSACTION_ID_MASK'], how='left')\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "600002d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL QUATITY BOUGHT BY CUSTOMER - CORRETO!\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_30_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='30D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_90_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='90D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_180_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='180D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_360_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='360D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67d73661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIQUE NUMBER OF SUBCATEGORIES BOUGHT - CORRETO!\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_30_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='30D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_90_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='90D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_180_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='180D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_360_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='360D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f57279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE DAYS FOR NEXT CUSTOMER'S TRANSACTION - CORRETO!\n",
    "\n",
    "df_uniques = df.copy()\n",
    "df_uniques['DAYS_FOR_NEXT_TRANSACTION'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK'])['TIME_KEY'].diff(-1).dt.days \\\n",
    "                                              .fillna(0).apply(lambda x: abs(x))\n",
    "df_uniques = df_uniques.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='last').reset_index()\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                   .rolling(window='30D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(30)\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_90_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                   .rolling(window='90D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(60)\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_180_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                    .rolling(window='180D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(180)\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_360_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                    .rolling(window='360D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(360)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "\n",
    "# Regression Feature - Average days for the next transaction in the next 30 days of a certain month, by customer\n",
    "\n",
    "ml_dataset['REG_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS'] = ml_dataset.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                    .CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS \\\n",
    "                                                                    .shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcbd0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE BASKET SIZE - CORRETO!\n",
    "\n",
    "df['CUST_NUM_SUBCAT_30_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='30D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_30_DAYS'] = df['CUST_NUM_SUBCAT_30_DAYS'] / df['CUST_NUM_TRANSACTIONS_30_DAYS']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_90_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='90D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_90_DAYS'] = df['CUST_NUM_SUBCAT_90_DAYS'] / df['CUST_NUM_TRANSACTIONS_90_DAYS']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_180_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='180D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_180_DAYS'] = df['CUST_NUM_SUBCAT_180_DAYS'] / df['CUST_NUM_TRANSACTIONS_180_DAYS']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_360_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='360D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_360_DAYS'] = df['CUST_NUM_SUBCAT_360_DAYS'] / df['CUST_NUM_TRANSACTIONS_360_DAYS']\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4087154b",
   "metadata": {},
   "source": [
    "Subcategory features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ed446ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['SUBCAT_CD_EXT','TIME_KEY'])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14aa99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS - CORRETO!\n",
    "\n",
    "df_uniques = df.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='first').reset_index()\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_30_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='30D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_90_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='90D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_180_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='180D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_360_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='360D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7328026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL QUATITY BOUGHT BY SUBCATEGORY - CORRETO!\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_30_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='30D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_90_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='90D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_180_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='180D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_360_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='360D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a3648ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIQUE NUMBER OF CUSTOMERS WHO BOUGHT FROM A SUBCATEGORY - CORRETO!\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_30_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='30D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_90_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='90D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_180_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='180D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_360_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='360D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b98bce3a",
   "metadata": {},
   "source": [
    "Customer-Subcategory features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "848079f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','TIME_KEY'])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4345f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS FOR A SUBCATEGORY BY A SPECIFIC CUSTOMER - CORRETO!\n",
    "\n",
    "df_uniques = df.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='first').reset_index()\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_30_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='30D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_90_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='90D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_180_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='180D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_360_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='360D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "875e4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL QUATITY BOUGHT BY CUSTOMER BY SUBCATEGORY - CORRETO!\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_30_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='30D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                              .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_90_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='90D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                              .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_180_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='180D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                               .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_360_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='360D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                               .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d380e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE DAYS FOR NEXT CUSTOMER'S TRANSACTION WITH A CERTAIN SUBCATEGORY - CORRETO!\n",
    "\n",
    "df_uniques = df.copy()\n",
    "df_uniques['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT'])['TIME_KEY'].diff(-1).dt.days \\\n",
    "                                              .fillna(0).apply(lambda x: abs(x))\n",
    "df_uniques = df_uniques.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='last').reset_index()\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                   .rolling(window='30D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(30)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_90_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                   .rolling(window='90D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(60)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_180_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                    .rolling(window='180D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(180)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_360_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                    .rolling(window='360D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(360)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5affcba2",
   "metadata": {},
   "source": [
    "Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3045e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = fill_missing_values(df)  # Fills the missing values of the customer column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6578e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "customer_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['GENDER']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['GENDER'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(customer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c25de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "family_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['FAMILY_MEMBERS']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['FAMILY_MEMBERS'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(family_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e904447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestyle_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['seg_lifestyle_cd']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['SEG_LIFESTYLE_CD'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(lifestyle_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22e1e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestage_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['seg_lifestage_cd']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['SEG_LIFESTAGE_CD'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(lifestage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da9c09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = client.query(\"\"\"\n",
    "   SELECT SUBCAT_CD_EXT, CAT_CD_EXT, PRICE_RANGE\n",
    "   FROM tables_raw.dim_product\n",
    "   \"\"\")\n",
    "\n",
    "products = query.result().to_dataframe() # Wait for the job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89950622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestage_dict = dict(zip(products['SUBCAT_CD_EXT'], products['CAT_CD_EXT']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['CAT_CD_EXT'] = ml_dataset['SUBCAT_CD_EXT'].map(lifestage_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffe6eeb2",
   "metadata": {},
   "source": [
    "Target features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d837c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dataset = ml_dataset.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','YEAR','MONTH'])\n",
    "ml_dataset = compute_target(ml_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85f5f290",
   "metadata": {},
   "source": [
    "# Load dataset into BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6ee6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataframe\n",
    "ml_dataset = ml_dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b07ba597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=continente-lced-feup, location=europe-southwest1, id=0295764b-6f0c-4a5a-bc9b-02f5485a7273>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### SAVE DATAFRAME TO BIGQUERY ####\n",
    "client.load_table_from_dataframe(ml_dataset, 'tables_staging.df_models').result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
