{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Install and Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41655,"status":"ok","timestamp":1683754027326,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"1l3_4sklgfVi","outputId":"e9ef4914-35b2-4cda-ee27-64bf29382d87"},"outputs":[],"source":["!pip install git+https://github.com/oracle/Skater.git"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3564,"status":"ok","timestamp":1683754030883,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"BDhC9ahTICDb"},"outputs":[],"source":["import pandas as pd\n","import heapq\n","import pickle\n","import numpy as np\n","import seaborn as sns\n","import random\n","import matplotlib.patches as mpatches\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from datetime import time\n","import sklearn\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import cross_val_score\n","from sklearn import svm, datasets\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","#from tabulate import tabulate\n","from sklearn import cluster\n","from sklearn.metrics import silhouette_score\n","from sklearn.linear_model import Perceptron\n","from timeit import timeit\n","from sklearn import datasets, tree\n","import datetime\n","import os\n","import warnings\n","warnings.simplefilter(action = 'ignore', category=FutureWarning)\n","warnings.filterwarnings('ignore')\n","def ignore_warn(*args, **kwargs):\n","    pass\n","warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n","import pylab \n","sns.set(style=\"ticks\", color_codes=True, font_scale=1.5)\n","from matplotlib import pyplot as plt\n","from matplotlib.ticker import FormatStrFormatter\n","from matplotlib.colors import ListedColormap\n","import matplotlib.colors as mcolors\n","%matplotlib inline\n","import mpl_toolkits\n","from mpl_toolkits.mplot3d import Axes3D\n","#from graphviz import Source\n","from IPython.display import Image\n","from scipy.stats import skew, norm, probplot, boxcox, f_oneway\n","from scipy import interp\n","from sklearn.base import BaseEstimator, TransformerMixin, clone, ClassifierMixin\n","from sklearn import metrics, tree\n","from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler, PolynomialFeatures, MinMaxScaler\n","from imblearn.over_sampling import SMOTE, RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.decomposition import PCA\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, cross_val_predict, train_test_split, RandomizedSearchCV\n","from sklearn.feature_selection import SequentialFeatureSelector\n","from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score\n","from sklearn.linear_model import LogisticRegression\n","# from keras.models import Sequential\n","# from keras.layers import Dense\n","# from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","#import xgboost as xgb\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.cluster import DBSCAN\n","#from mlxtend.classifier import StackingClassifier\n","from skater.core.local_interpretation.lime.lime_tabular import LimeTabularExplainer\n","from skater.core.explanations import Interpretation\n","from skater.model import InMemoryModel\n","import scipy\n","from sklearn.model_selection import GridSearchCV\n","from google.cloud import bigquery\n","from sklearn.model_selection import TimeSeriesSplit\n","from scipy.stats import chi2_contingency\n","import joblib"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Loading the Data"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1303,"status":"ok","timestamp":1683754081142,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"g3BbQ3ceIF3D"},"outputs":[],"source":["# set display options to show all columns\n","pd.set_option('display.max_columns', None)\n","# Set the float format to display numbers without scientific notation\n","pd.options.display.float_format = '{:.2f}'.format\n","# Set the client for future queries to BigQuery\n","client = bigquery.Client(project = \"continente-lced-feup\")\n","#data_table.enable_dataframe_formatter()\n","#auth.authenticate_user()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48971,"status":"ok","timestamp":1683754079843,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"-RODB9NDIF53","outputId":"f8217fef-ca72-4cb4-b0d6-a1aeb2a278eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Your browser has been opened to visit:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=JJCcGBH0IyS5UOHnrcCARNvYrHwAni&access_type=offline&code_challenge=SO72YByDPBmdy4xjwG_tpoSSFfOl9Y0KO7fF1lY6dtQ&code_challenge_method=S256\n","\n","\n","Credentials saved to file: [/Users/henriqueribeiro/.config/gcloud/application_default_credentials.json]\n","\n","These credentials will be used by any library that requests Application Default Credentials (ADC).\n","\n","Quota project \"continente-lced-feup\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"]}],"source":["!gcloud auth application-default login"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"elapsed":9109,"status":"ok","timestamp":1683754090249,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"yjHx6fYlIF8A","outputId":"5ae67c63-4db2-4d40-e29b-044ab14332d9"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CUSTOMER_ACCOUNT_NR_MASK</th>\n","      <th>SUBCAT_CD_EXT</th>\n","      <th>MONTH</th>\n","      <th>YEAR</th>\n","      <th>QUARTER</th>\n","      <th>SEMESTER</th>\n","      <th>CUST_NUM_TRANSACTIONS_MONTH</th>\n","      <th>CUST_NUM_TRANSACTIONS_QUARTER</th>\n","      <th>CUST_NUM_TRANSACTIONS_SEMESTER</th>\n","      <th>CUST_NUM_TRANSACTIONS_YEAR</th>\n","      <th>CUST_TOTAL_QTY_BOUGHT_MONTH</th>\n","      <th>CUST_TOTAL_QTY_BOUGHT_QUARTER</th>\n","      <th>CUST_TOTAL_QTY_BOUGHT_SEMESTER</th>\n","      <th>CUST_TOTAL_QTY_BOUGHT_YEAR</th>\n","      <th>CUST_NUM_UNIQUE_SUBCAT_MONTH</th>\n","      <th>CUST_NUM_UNIQUE_SUBCAT_QUARTER</th>\n","      <th>CUST_NUM_UNIQUE_SUBCAT_SEMESTER</th>\n","      <th>CUST_NUM_UNIQUE_SUBCAT_YEAR</th>\n","      <th>CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH</th>\n","      <th>CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_QUARTER</th>\n","      <th>CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_SEMESTER</th>\n","      <th>CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_YEAR</th>\n","      <th>REG_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH</th>\n","      <th>CUST_AVG_BASKET_SIZE_MONTH</th>\n","      <th>CUST_AVG_BASKET_SIZE_QUARTER</th>\n","      <th>CUST_AVG_BASKET_SIZE_SEMESTER</th>\n","      <th>CUST_AVG_BASKET_SIZE_YEAR</th>\n","      <th>SUBCAT_NUM_TRANSACTIONS_MONTH</th>\n","      <th>SUBCAT_NUM_TRANSACTIONS_QUARTER</th>\n","      <th>SUBCAT_NUM_TRANSACTIONS_SEMESTER</th>\n","      <th>SUBCAT_NUM_TRANSACTIONS_YEAR</th>\n","      <th>SUBCAT_TOTAL_QTY_BOUGHT_MONTH</th>\n","      <th>SUBCAT_TOTAL_QTY_BOUGHT_QUARTER</th>\n","      <th>SUBCAT_TOTAL_QTY_BOUGHT_SEMESTER</th>\n","      <th>SUBCAT_TOTAL_QTY_BOUGHT_YEAR</th>\n","      <th>SUBCAT_NUM_UNIQUE_CUST_MONTH</th>\n","      <th>SUBCAT_NUM_UNIQUE_CUST_QUARTER</th>\n","      <th>SUBCAT_NUM_UNIQUE_CUST_SEMESTER</th>\n","      <th>SUBCAT_NUM_UNIQUE_CUST_YEAR</th>\n","      <th>CUSTSUBCAT_NUM_TRANSACTIONS_MONTH</th>\n","      <th>CUSTSUBCAT_NUM_TRANSACTIONS_QUARTER</th>\n","      <th>CUSTSUBCAT_NUM_TRANSACTIONS_SEMESTER</th>\n","      <th>CUSTSUBCAT_NUM_TRANSACTIONS_YEAR</th>\n","      <th>CUSTSUBCAT_TOTAL_QTY_BOUGHT_MONTH</th>\n","      <th>CUSTSUBCAT_TOTAL_QTY_BOUGHT_QUARTER</th>\n","      <th>CUSTSUBCAT_TOTAL_QTY_BOUGHT_SEMESTER</th>\n","      <th>CUSTSUBCAT_TOTAL_QTY_BOUGHT_YEAR</th>\n","      <th>CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH</th>\n","      <th>CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_QUARTER</th>\n","      <th>CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_SEMESTER</th>\n","      <th>CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_YEAR</th>\n","      <th>GENDER</th>\n","      <th>FAMILY_MEMBERS</th>\n","      <th>SEG_LIFESTYLE_CD</th>\n","      <th>SEG_LIFESTAGE_CD</th>\n","      <th>CAT_CD_EXT</th>\n","      <th>TARGET</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37912</td>\n","      <td>10101</td>\n","      <td>1</td>\n","      <td>2021</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>24</td>\n","      <td>24</td>\n","      <td>24</td>\n","      <td>24</td>\n","      <td>12</td>\n","      <td>12</td>\n","      <td>12</td>\n","      <td>12</td>\n","      <td>2.25</td>\n","      <td>2.25</td>\n","      <td>2.25</td>\n","      <td>2.25</td>\n","      <td>4.20</td>\n","      <td>3.60</td>\n","      <td>3.60</td>\n","      <td>3.60</td>\n","      <td>3.60</td>\n","      <td>2733</td>\n","      <td>2733</td>\n","      <td>2733</td>\n","      <td>2733</td>\n","      <td>4304</td>\n","      <td>4304</td>\n","      <td>4304</td>\n","      <td>4304</td>\n","      <td>1741</td>\n","      <td>1741</td>\n","      <td>1741</td>\n","      <td>1741</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>M</td>\n","      <td>(3, 8)</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>101</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>37912</td>\n","      <td>10101</td>\n","      <td>2</td>\n","      <td>2021</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>46</td>\n","      <td>70</td>\n","      <td>70</td>\n","      <td>70</td>\n","      <td>20</td>\n","      <td>27</td>\n","      <td>27</td>\n","      <td>27</td>\n","      <td>4.20</td>\n","      <td>5.30</td>\n","      <td>5.30</td>\n","      <td>5.30</td>\n","      <td>2.40</td>\n","      <td>5.50</td>\n","      <td>4.64</td>\n","      <td>4.64</td>\n","      <td>4.64</td>\n","      <td>2640</td>\n","      <td>5373</td>\n","      <td>5373</td>\n","      <td>5373</td>\n","      <td>4140</td>\n","      <td>8444</td>\n","      <td>8444</td>\n","      <td>8444</td>\n","      <td>1676</td>\n","      <td>2504</td>\n","      <td>2504</td>\n","      <td>2504</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>M</td>\n","      <td>(3, 8)</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>101</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>37912</td>\n","      <td>10101</td>\n","      <td>3</td>\n","      <td>2021</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>22</td>\n","      <td>22</td>\n","      <td>22</td>\n","      <td>60</td>\n","      <td>130</td>\n","      <td>130</td>\n","      <td>130</td>\n","      <td>21</td>\n","      <td>37</td>\n","      <td>37</td>\n","      <td>37</td>\n","      <td>2.40</td>\n","      <td>3.86</td>\n","      <td>3.86</td>\n","      <td>3.86</td>\n","      <td>5.20</td>\n","      <td>3.55</td>\n","      <td>4.09</td>\n","      <td>4.09</td>\n","      <td>4.09</td>\n","      <td>2924</td>\n","      <td>8297</td>\n","      <td>8297</td>\n","      <td>8297</td>\n","      <td>4686</td>\n","      <td>13130</td>\n","      <td>13130</td>\n","      <td>13130</td>\n","      <td>1863</td>\n","      <td>3090</td>\n","      <td>3090</td>\n","      <td>3090</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>9.00</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>M</td>\n","      <td>(3, 8)</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>101</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>37912</td>\n","      <td>10101</td>\n","      <td>4</td>\n","      <td>2021</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>28</td>\n","      <td>28</td>\n","      <td>29</td>\n","      <td>29</td>\n","      <td>159</td>\n","      <td>159</td>\n","      <td>13</td>\n","      <td>13</td>\n","      <td>39</td>\n","      <td>39</td>\n","      <td>5.20</td>\n","      <td>5.20</td>\n","      <td>4.11</td>\n","      <td>4.11</td>\n","      <td>6.00</td>\n","      <td>4.17</td>\n","      <td>4.17</td>\n","      <td>4.11</td>\n","      <td>4.11</td>\n","      <td>2577</td>\n","      <td>2577</td>\n","      <td>10874</td>\n","      <td>10874</td>\n","      <td>4200</td>\n","      <td>4200</td>\n","      <td>17330</td>\n","      <td>17330</td>\n","      <td>1760</td>\n","      <td>1760</td>\n","      <td>3511</td>\n","      <td>3511</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>12.00</td>\n","      <td>12</td>\n","      <td>13</td>\n","      <td>13</td>\n","      <td>M</td>\n","      <td>(3, 8)</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>101</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37912</td>\n","      <td>10101</td>\n","      <td>5</td>\n","      <td>2021</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>11</td>\n","      <td>33</td>\n","      <td>33</td>\n","      <td>31</td>\n","      <td>60</td>\n","      <td>190</td>\n","      <td>190</td>\n","      <td>13</td>\n","      <td>20</td>\n","      <td>44</td>\n","      <td>44</td>\n","      <td>6.00</td>\n","      <td>5.50</td>\n","      <td>4.38</td>\n","      <td>4.38</td>\n","      <td>3.57</td>\n","      <td>4.20</td>\n","      <td>4.18</td>\n","      <td>4.12</td>\n","      <td>4.12</td>\n","      <td>2824</td>\n","      <td>5401</td>\n","      <td>13698</td>\n","      <td>13698</td>\n","      <td>4815</td>\n","      <td>9015</td>\n","      <td>22145</td>\n","      <td>22145</td>\n","      <td>1885</td>\n","      <td>2731</td>\n","      <td>3890</td>\n","      <td>3890</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>0.00</td>\n","      <td>20</td>\n","      <td>17</td>\n","      <td>17</td>\n","      <td>M</td>\n","      <td>(3, 8)</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>101</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3365383</th>\n","      <td>130366108</td>\n","      <td>170313</td>\n","      <td>8</td>\n","      <td>2022</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>21</td>\n","      <td>21</td>\n","      <td>55</td>\n","      <td>67</td>\n","      <td>142</td>\n","      <td>142</td>\n","      <td>463</td>\n","      <td>25</td>\n","      <td>43</td>\n","      <td>43</td>\n","      <td>67</td>\n","      <td>3.00</td>\n","      <td>2.70</td>\n","      <td>2.70</td>\n","      <td>4.28</td>\n","      <td>2.67</td>\n","      <td>6.11</td>\n","      <td>5.19</td>\n","      <td>5.19</td>\n","      <td>5.84</td>\n","      <td>106</td>\n","      <td>191</td>\n","      <td>191</td>\n","      <td>618</td>\n","      <td>190</td>\n","      <td>318</td>\n","      <td>318</td>\n","      <td>912</td>\n","      <td>93</td>\n","      <td>158</td>\n","      <td>158</td>\n","      <td>443</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>M</td>\n","      <td>(3, 8)</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1703</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3365384</th>\n","      <td>130366108</td>\n","      <td>170313</td>\n","      <td>9</td>\n","      <td>2022</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>31</td>\n","      <td>31</td>\n","      <td>65</td>\n","      <td>76</td>\n","      <td>218</td>\n","      <td>218</td>\n","      <td>539</td>\n","      <td>25</td>\n","      <td>51</td>\n","      <td>51</td>\n","      <td>69</td>\n","      <td>2.67</td>\n","      <td>2.93</td>\n","      <td>2.93</td>\n","      <td>4.14</td>\n","      <td>4.00</td>\n","      <td>5.80</td>\n","      <td>5.39</td>\n","      <td>5.39</td>\n","      <td>5.83</td>\n","      <td>67</td>\n","      <td>258</td>\n","      <td>258</td>\n","      <td>685</td>\n","      <td>89</td>\n","      <td>407</td>\n","      <td>407</td>\n","      <td>1001</td>\n","      <td>63</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>485</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>M</td>\n","      <td>(3, 8)</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1703</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3365385</th>\n","      <td>130366108</td>\n","      <td>170313</td>\n","      <td>10</td>\n","      <td>2022</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>38</td>\n","      <td>72</td>\n","      <td>18</td>\n","      <td>18</td>\n","      <td>236</td>\n","      <td>557</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>54</td>\n","      <td>70</td>\n","      <td>4.00</td>\n","      <td>4.00</td>\n","      <td>3.27</td>\n","      <td>4.20</td>\n","      <td>4.80</td>\n","      <td>1.86</td>\n","      <td>1.86</td>\n","      <td>4.74</td>\n","      <td>5.44</td>\n","      <td>78</td>\n","      <td>78</td>\n","      <td>336</td>\n","      <td>763</td>\n","      <td>118</td>\n","      <td>118</td>\n","      <td>525</td>\n","      <td>1119</td>\n","      <td>71</td>\n","      <td>71</td>\n","      <td>268</td>\n","      <td>533</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>M</td>\n","      <td>(3, 8)</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1703</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3365386</th>\n","      <td>130366108</td>\n","      <td>170313</td>\n","      <td>11</td>\n","      <td>2022</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>13</td>\n","      <td>44</td>\n","      <td>78</td>\n","      <td>54</td>\n","      <td>72</td>\n","      <td>290</td>\n","      <td>611</td>\n","      <td>18</td>\n","      <td>24</td>\n","      <td>57</td>\n","      <td>71</td>\n","      <td>4.80</td>\n","      <td>4.33</td>\n","      <td>3.47</td>\n","      <td>4.23</td>\n","      <td>2.75</td>\n","      <td>4.33</td>\n","      <td>3.00</td>\n","      <td>4.68</td>\n","      <td>5.36</td>\n","      <td>77</td>\n","      <td>155</td>\n","      <td>413</td>\n","      <td>840</td>\n","      <td>105</td>\n","      <td>223</td>\n","      <td>630</td>\n","      <td>1224</td>\n","      <td>65</td>\n","      <td>131</td>\n","      <td>316</td>\n","      <td>568</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>M</td>\n","      <td>(3, 8)</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1703</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3365387</th>\n","      <td>130366108</td>\n","      <td>170313</td>\n","      <td>12</td>\n","      <td>2022</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>22</td>\n","      <td>53</td>\n","      <td>87</td>\n","      <td>120</td>\n","      <td>192</td>\n","      <td>410</td>\n","      <td>731</td>\n","      <td>23</td>\n","      <td>34</td>\n","      <td>60</td>\n","      <td>72</td>\n","      <td>2.75</td>\n","      <td>3.67</td>\n","      <td>3.35</td>\n","      <td>4.08</td>\n","      <td>NaN</td>\n","      <td>7.33</td>\n","      <td>4.77</td>\n","      <td>5.13</td>\n","      <td>5.56</td>\n","      <td>300</td>\n","      <td>455</td>\n","      <td>713</td>\n","      <td>1140</td>\n","      <td>448</td>\n","      <td>671</td>\n","      <td>1078</td>\n","      <td>1672</td>\n","      <td>266</td>\n","      <td>367</td>\n","      <td>527</td>\n","      <td>747</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>M</td>\n","      <td>(3, 8)</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1703</td>\n","      <td>&lt;NA&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3365388 rows × 57 columns</p>\n","</div>"],"text/plain":["         CUSTOMER_ACCOUNT_NR_MASK  SUBCAT_CD_EXT  MONTH  YEAR  QUARTER  \\\n","0                           37912          10101      1  2021        1   \n","1                           37912          10101      2  2021        1   \n","2                           37912          10101      3  2021        1   \n","3                           37912          10101      4  2021        2   \n","4                           37912          10101      5  2021        2   \n","...                           ...            ...    ...   ...      ...   \n","3365383                 130366108         170313      8  2022        3   \n","3365384                 130366108         170313      9  2022        3   \n","3365385                 130366108         170313     10  2022        4   \n","3365386                 130366108         170313     11  2022        4   \n","3365387                 130366108         170313     12  2022        4   \n","\n","         SEMESTER  CUST_NUM_TRANSACTIONS_MONTH  CUST_NUM_TRANSACTIONS_QUARTER  \\\n","0               1                            5                              5   \n","1               1                            6                             11   \n","2               1                           11                             22   \n","3               1                            6                              6   \n","4               1                            5                             11   \n","...           ...                          ...                            ...   \n","3365383         2                            9                             21   \n","3365384         2                           10                             31   \n","3365385         2                            7                              7   \n","3365386         2                            6                             13   \n","3365387         2                            9                             22   \n","\n","         CUST_NUM_TRANSACTIONS_SEMESTER  CUST_NUM_TRANSACTIONS_YEAR  \\\n","0                                     5                           5   \n","1                                    11                          11   \n","2                                    22                          22   \n","3                                    28                          28   \n","4                                    33                          33   \n","...                                 ...                         ...   \n","3365383                              21                          55   \n","3365384                              31                          65   \n","3365385                              38                          72   \n","3365386                              44                          78   \n","3365387                              53                          87   \n","\n","         CUST_TOTAL_QTY_BOUGHT_MONTH  CUST_TOTAL_QTY_BOUGHT_QUARTER  \\\n","0                                 24                             24   \n","1                                 46                             70   \n","2                                 60                            130   \n","3                                 29                             29   \n","4                                 31                             60   \n","...                              ...                            ...   \n","3365383                           67                            142   \n","3365384                           76                            218   \n","3365385                           18                             18   \n","3365386                           54                             72   \n","3365387                          120                            192   \n","\n","         CUST_TOTAL_QTY_BOUGHT_SEMESTER  CUST_TOTAL_QTY_BOUGHT_YEAR  \\\n","0                                    24                          24   \n","1                                    70                          70   \n","2                                   130                         130   \n","3                                   159                         159   \n","4                                   190                         190   \n","...                                 ...                         ...   \n","3365383                             142                         463   \n","3365384                             218                         539   \n","3365385                             236                         557   \n","3365386                             290                         611   \n","3365387                             410                         731   \n","\n","         CUST_NUM_UNIQUE_SUBCAT_MONTH  CUST_NUM_UNIQUE_SUBCAT_QUARTER  \\\n","0                                  12                              12   \n","1                                  20                              27   \n","2                                  21                              37   \n","3                                  13                              13   \n","4                                  13                              20   \n","...                               ...                             ...   \n","3365383                            25                              43   \n","3365384                            25                              51   \n","3365385                            10                              10   \n","3365386                            18                              24   \n","3365387                            23                              34   \n","\n","         CUST_NUM_UNIQUE_SUBCAT_SEMESTER  CUST_NUM_UNIQUE_SUBCAT_YEAR  \\\n","0                                     12                           12   \n","1                                     27                           27   \n","2                                     37                           37   \n","3                                     39                           39   \n","4                                     44                           44   \n","...                                  ...                          ...   \n","3365383                               43                           67   \n","3365384                               51                           69   \n","3365385                               54                           70   \n","3365386                               57                           71   \n","3365387                               60                           72   \n","\n","         CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH  \\\n","0                                               2.25   \n","1                                               4.20   \n","2                                               2.40   \n","3                                               5.20   \n","4                                               6.00   \n","...                                              ...   \n","3365383                                         3.00   \n","3365384                                         2.67   \n","3365385                                         4.00   \n","3365386                                         4.80   \n","3365387                                         2.75   \n","\n","         CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_QUARTER  \\\n","0                                                 2.25   \n","1                                                 5.30   \n","2                                                 3.86   \n","3                                                 5.20   \n","4                                                 5.50   \n","...                                                ...   \n","3365383                                           2.70   \n","3365384                                           2.93   \n","3365385                                           4.00   \n","3365386                                           4.33   \n","3365387                                           3.67   \n","\n","         CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_SEMESTER  \\\n","0                                                  2.25   \n","1                                                  5.30   \n","2                                                  3.86   \n","3                                                  4.11   \n","4                                                  4.38   \n","...                                                 ...   \n","3365383                                            2.70   \n","3365384                                            2.93   \n","3365385                                            3.27   \n","3365386                                            3.47   \n","3365387                                            3.35   \n","\n","         CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_YEAR  \\\n","0                                              2.25   \n","1                                              5.30   \n","2                                              3.86   \n","3                                              4.11   \n","4                                              4.38   \n","...                                             ...   \n","3365383                                        4.28   \n","3365384                                        4.14   \n","3365385                                        4.20   \n","3365386                                        4.23   \n","3365387                                        4.08   \n","\n","         REG_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH  \\\n","0                                              4.20   \n","1                                              2.40   \n","2                                              5.20   \n","3                                              6.00   \n","4                                              3.57   \n","...                                             ...   \n","3365383                                        2.67   \n","3365384                                        4.00   \n","3365385                                        4.80   \n","3365386                                        2.75   \n","3365387                                         NaN   \n","\n","         CUST_AVG_BASKET_SIZE_MONTH  CUST_AVG_BASKET_SIZE_QUARTER  \\\n","0                              3.60                          3.60   \n","1                              5.50                          4.64   \n","2                              3.55                          4.09   \n","3                              4.17                          4.17   \n","4                              4.20                          4.18   \n","...                             ...                           ...   \n","3365383                        6.11                          5.19   \n","3365384                        5.80                          5.39   \n","3365385                        1.86                          1.86   \n","3365386                        4.33                          3.00   \n","3365387                        7.33                          4.77   \n","\n","         CUST_AVG_BASKET_SIZE_SEMESTER  CUST_AVG_BASKET_SIZE_YEAR  \\\n","0                                 3.60                       3.60   \n","1                                 4.64                       4.64   \n","2                                 4.09                       4.09   \n","3                                 4.11                       4.11   \n","4                                 4.12                       4.12   \n","...                                ...                        ...   \n","3365383                           5.19                       5.84   \n","3365384                           5.39                       5.83   \n","3365385                           4.74                       5.44   \n","3365386                           4.68                       5.36   \n","3365387                           5.13                       5.56   \n","\n","         SUBCAT_NUM_TRANSACTIONS_MONTH  SUBCAT_NUM_TRANSACTIONS_QUARTER  \\\n","0                                 2733                             2733   \n","1                                 2640                             5373   \n","2                                 2924                             8297   \n","3                                 2577                             2577   \n","4                                 2824                             5401   \n","...                                ...                              ...   \n","3365383                            106                              191   \n","3365384                             67                              258   \n","3365385                             78                               78   \n","3365386                             77                              155   \n","3365387                            300                              455   \n","\n","         SUBCAT_NUM_TRANSACTIONS_SEMESTER  SUBCAT_NUM_TRANSACTIONS_YEAR  \\\n","0                                    2733                          2733   \n","1                                    5373                          5373   \n","2                                    8297                          8297   \n","3                                   10874                         10874   \n","4                                   13698                         13698   \n","...                                   ...                           ...   \n","3365383                               191                           618   \n","3365384                               258                           685   \n","3365385                               336                           763   \n","3365386                               413                           840   \n","3365387                               713                          1140   \n","\n","         SUBCAT_TOTAL_QTY_BOUGHT_MONTH  SUBCAT_TOTAL_QTY_BOUGHT_QUARTER  \\\n","0                                 4304                             4304   \n","1                                 4140                             8444   \n","2                                 4686                            13130   \n","3                                 4200                             4200   \n","4                                 4815                             9015   \n","...                                ...                              ...   \n","3365383                            190                              318   \n","3365384                             89                              407   \n","3365385                            118                              118   \n","3365386                            105                              223   \n","3365387                            448                              671   \n","\n","         SUBCAT_TOTAL_QTY_BOUGHT_SEMESTER  SUBCAT_TOTAL_QTY_BOUGHT_YEAR  \\\n","0                                    4304                          4304   \n","1                                    8444                          8444   \n","2                                   13130                         13130   \n","3                                   17330                         17330   \n","4                                   22145                         22145   \n","...                                   ...                           ...   \n","3365383                               318                           912   \n","3365384                               407                          1001   \n","3365385                               525                          1119   \n","3365386                               630                          1224   \n","3365387                              1078                          1672   \n","\n","         SUBCAT_NUM_UNIQUE_CUST_MONTH  SUBCAT_NUM_UNIQUE_CUST_QUARTER  \\\n","0                                1741                            1741   \n","1                                1676                            2504   \n","2                                1863                            3090   \n","3                                1760                            1760   \n","4                                1885                            2731   \n","...                               ...                             ...   \n","3365383                            93                             158   \n","3365384                            63                             207   \n","3365385                            71                              71   \n","3365386                            65                             131   \n","3365387                           266                             367   \n","\n","         SUBCAT_NUM_UNIQUE_CUST_SEMESTER  SUBCAT_NUM_UNIQUE_CUST_YEAR  \\\n","0                                   1741                         1741   \n","1                                   2504                         2504   \n","2                                   3090                         3090   \n","3                                   3511                         3511   \n","4                                   3890                         3890   \n","...                                  ...                          ...   \n","3365383                              158                          443   \n","3365384                              207                          485   \n","3365385                              268                          533   \n","3365386                              316                          568   \n","3365387                              527                          747   \n","\n","         CUSTSUBCAT_NUM_TRANSACTIONS_MONTH  \\\n","0                                        0   \n","1                                        0   \n","2                                        2   \n","3                                        2   \n","4                                        1   \n","...                                    ...   \n","3365383                                  0   \n","3365384                                  0   \n","3365385                                  0   \n","3365386                                  0   \n","3365387                                  0   \n","\n","         CUSTSUBCAT_NUM_TRANSACTIONS_QUARTER  \\\n","0                                          0   \n","1                                          0   \n","2                                          2   \n","3                                          2   \n","4                                          3   \n","...                                      ...   \n","3365383                                    1   \n","3365384                                    1   \n","3365385                                    0   \n","3365386                                    0   \n","3365387                                    0   \n","\n","         CUSTSUBCAT_NUM_TRANSACTIONS_SEMESTER  \\\n","0                                           0   \n","1                                           0   \n","2                                           2   \n","3                                           4   \n","4                                           5   \n","...                                       ...   \n","3365383                                     1   \n","3365384                                     1   \n","3365385                                     1   \n","3365386                                     1   \n","3365387                                     1   \n","\n","         CUSTSUBCAT_NUM_TRANSACTIONS_YEAR  CUSTSUBCAT_TOTAL_QTY_BOUGHT_MONTH  \\\n","0                                       0                                  0   \n","1                                       0                                  0   \n","2                                       2                                  3   \n","3                                       4                                  4   \n","4                                       5                                  1   \n","...                                   ...                                ...   \n","3365383                                 2                                  0   \n","3365384                                 2                                  0   \n","3365385                                 2                                  0   \n","3365386                                 2                                  0   \n","3365387                                 2                                  0   \n","\n","         CUSTSUBCAT_TOTAL_QTY_BOUGHT_QUARTER  \\\n","0                                          0   \n","1                                          0   \n","2                                          3   \n","3                                          4   \n","4                                          5   \n","...                                      ...   \n","3365383                                    1   \n","3365384                                    1   \n","3365385                                    0   \n","3365386                                    0   \n","3365387                                    0   \n","\n","         CUSTSUBCAT_TOTAL_QTY_BOUGHT_SEMESTER  \\\n","0                                           0   \n","1                                           0   \n","2                                           3   \n","3                                           7   \n","4                                           8   \n","...                                       ...   \n","3365383                                     1   \n","3365384                                     1   \n","3365385                                     1   \n","3365386                                     1   \n","3365387                                     1   \n","\n","         CUSTSUBCAT_TOTAL_QTY_BOUGHT_YEAR  \\\n","0                                       0   \n","1                                       0   \n","2                                       3   \n","3                                       7   \n","4                                       8   \n","...                                   ...   \n","3365383                                 2   \n","3365384                                 2   \n","3365385                                 2   \n","3365386                                 2   \n","3365387                                 2   \n","\n","         CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH  \\\n","0                                                     0.00   \n","1                                                     0.00   \n","2                                                     9.00   \n","3                                                    12.00   \n","4                                                     0.00   \n","...                                                    ...   \n","3365383                                               0.00   \n","3365384                                               0.00   \n","3365385                                               0.00   \n","3365386                                               0.00   \n","3365387                                               0.00   \n","\n","         CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_QUARTER  \\\n","0                                                        0     \n","1                                                        0     \n","2                                                        9     \n","3                                                       12     \n","4                                                       20     \n","...                                                    ...     \n","3365383                                                  0     \n","3365384                                                  0     \n","3365385                                                  0     \n","3365386                                                  0     \n","3365387                                                  0     \n","\n","         CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_SEMESTER  \\\n","0                                                        0      \n","1                                                        0      \n","2                                                        9      \n","3                                                       13      \n","4                                                       17      \n","...                                                    ...      \n","3365383                                                  0      \n","3365384                                                  0      \n","3365385                                                  0      \n","3365386                                                  0      \n","3365387                                                  0      \n","\n","         CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_YEAR GENDER  \\\n","0                                                       0      M   \n","1                                                       0      M   \n","2                                                       9      M   \n","3                                                      13      M   \n","4                                                      17      M   \n","...                                                   ...    ...   \n","3365383                                                12      M   \n","3365384                                                12      M   \n","3365385                                                12      M   \n","3365386                                                12      M   \n","3365387                                                12      M   \n","\n","        FAMILY_MEMBERS  SEG_LIFESTYLE_CD  SEG_LIFESTAGE_CD  CAT_CD_EXT  TARGET  \n","0               (3, 8)                 2                 4         101       0  \n","1               (3, 8)                 2                 4         101       1  \n","2               (3, 8)                 2                 4         101       1  \n","3               (3, 8)                 2                 4         101       1  \n","4               (3, 8)                 2                 4         101       1  \n","...                ...               ...               ...         ...     ...  \n","3365383         (3, 8)                 1                 4        1703       0  \n","3365384         (3, 8)                 1                 4        1703       0  \n","3365385         (3, 8)                 1                 4        1703       0  \n","3365386         (3, 8)                 1                 4        1703       0  \n","3365387         (3, 8)                 1                 4        1703    <NA>  \n","\n","[3365388 rows x 57 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["query = client.query(\"\"\"\n","   SELECT *\n","   FROM \n","       tables_staging.df_bold_model\n","    ORDER BY CUSTOMER_ACCOUNT_NR_MASK ASC, SUBCAT_CD_EXT ASC, YEAR ASC, MONTH ASC\n","   \"\"\")\n","\n","df = query.result().to_dataframe() # Wait for the job to complete.\n","df"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["query_products = client.query(\"\"\"\n","   SELECT *\n","   FROM \n","       tables_raw.dim_product\n","  LIMIT 6000000\n","   \"\"\")\n","\n","pdct_df = query_products.result().to_dataframe() # Wait for the job to complete."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["pdct_df = pdct_df[['SUBCAT_CD_EXT', 'SUBCAT_DSC_EXT']]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LaBORSavJiC_"},"source":["## Data Preparation"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12256,"status":"ok","timestamp":1683754102499,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"CiaXBFcOPyfH"},"outputs":[],"source":["\n","\n","# Specify the columns to drop null values except for\n","columns_to_exclude = ['TARGET', 'REG_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH']\n","\n","# Drop null values except for the specified columns\n","df = df.dropna(subset=[col for col in df.columns if col not in columns_to_exclude])\n","\n","\n","#df = df.dropna()\n","df = df.drop_duplicates()\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["\n","df['fulldate'] = pd.to_datetime(df['MONTH'].astype(str) + '-' + df['YEAR'].astype(str))\n","# change from dtype datetime64[ns] to date time month\n","df['fulldate'] = df['fulldate'].dt.to_period('M')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["df_sample = df.groupby('fulldate').sample(frac=1, random_state=101)\n","\n","#drop customer id column because we want to generalize the model, instead of trying to predict for each customer\n","df_sample = df_sample.drop(columns=['CUSTOMER_ACCOUNT_NR_MASK','REG_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH'])\n","\n","#df_500k.value_counts('fulldate').sort_index()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["(3365388, 56)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Function to replace outliers with average value of the column\n","def replace_outliers_with_average(df_non_minmax, column):\n","    # Calculate the lower and upper bounds for outliers using the boxplot rule\n","    q1 = df_non_minmax[column].quantile(0.25)\n","    q3 = df_non_minmax[column].quantile(0.75)\n","    iqr = q3 - q1\n","    lower_bound = q1 - 1.5 * iqr\n","    upper_bound = q3 + 1.5 * iqr\n","    \n","    # Replace outliers with the average value of the column\n","    avg_value = df_non_minmax[column].mean()\n","    df_non_minmax[column] = df_non_minmax[column].apply(lambda x: avg_value if x < lower_bound or x > upper_bound else x)\n","    \n","    return df_non_minmax\n","\n","# Detect outliers and replace them with average for each column in 'columns_to_check'\n","numerical_columns = ['CUST_NUM_TRANSACTIONS_MONTH', 'CUST_NUM_TRANSACTIONS_QUARTER',\n","       'CUST_NUM_TRANSACTIONS_SEMESTER', 'CUST_NUM_TRANSACTIONS_YEAR',\n","       'CUST_TOTAL_QTY_BOUGHT_MONTH', 'CUST_TOTAL_QTY_BOUGHT_QUARTER',\n","       'CUST_TOTAL_QTY_BOUGHT_SEMESTER', 'CUST_TOTAL_QTY_BOUGHT_YEAR',\n","       'CUST_NUM_UNIQUE_SUBCAT_MONTH', 'CUST_NUM_UNIQUE_SUBCAT_QUARTER',\n","       'CUST_NUM_UNIQUE_SUBCAT_SEMESTER', 'CUST_NUM_UNIQUE_SUBCAT_YEAR',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_QUARTER',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_SEMESTER',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_YEAR',\n","       'CUST_AVG_BASKET_SIZE_MONTH', 'CUST_AVG_BASKET_SIZE_QUARTER',\n","       'CUST_AVG_BASKET_SIZE_SEMESTER', 'CUST_AVG_BASKET_SIZE_YEAR',\n","       'SUBCAT_NUM_TRANSACTIONS_MONTH', 'SUBCAT_NUM_TRANSACTIONS_QUARTER',\n","       'SUBCAT_NUM_TRANSACTIONS_SEMESTER', 'SUBCAT_NUM_TRANSACTIONS_YEAR',\n","       'SUBCAT_TOTAL_QTY_BOUGHT_MONTH', 'SUBCAT_TOTAL_QTY_BOUGHT_QUARTER',\n","       'SUBCAT_TOTAL_QTY_BOUGHT_SEMESTER', 'SUBCAT_TOTAL_QTY_BOUGHT_YEAR',\n","       'SUBCAT_NUM_UNIQUE_CUST_MONTH', 'SUBCAT_NUM_UNIQUE_CUST_QUARTER',\n","       'SUBCAT_NUM_UNIQUE_CUST_SEMESTER', 'SUBCAT_NUM_UNIQUE_CUST_YEAR',\n","       'CUSTSUBCAT_NUM_TRANSACTIONS_MONTH',\n","       'CUSTSUBCAT_NUM_TRANSACTIONS_QUARTER',\n","       'CUSTSUBCAT_NUM_TRANSACTIONS_SEMESTER',\n","       'CUSTSUBCAT_NUM_TRANSACTIONS_YEAR', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT_MONTH',\n","       'CUSTSUBCAT_TOTAL_QTY_BOUGHT_QUARTER',\n","       'CUSTSUBCAT_TOTAL_QTY_BOUGHT_SEMESTER',\n","       'CUSTSUBCAT_TOTAL_QTY_BOUGHT_YEAR',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_QUARTER',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_SEMESTER',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_YEAR']\n","\n","for column in numerical_columns:\n","    df_sample = replace_outliers_with_average(df_sample, column)\n","    \n","df_sample.shape"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":426,"status":"ok","timestamp":1683754102919,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"F5Z-ppPkIGB4"},"outputs":[],"source":["scaler = MinMaxScaler()\n","df_sample[numerical_columns] = scaler.fit_transform(df_sample[numerical_columns])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dULFfLrTQjqM"},"source":["## Feature selection: Filter methods - No need to run"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1683754102920,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"TqKan9Es5eia"},"outputs":[],"source":["def our_heatmap(df_values, pv, threshold=1.1):\n","    \n","    # Define the colors\n","    colors = ['#84161a', '#fcf2f2']\n","\n","    # Create a list of relative positions for each color\n","    positions = [0, 1]\n","\n","    # Create the custom colormap\n","    cmap = mcolors.LinearSegmentedColormap.from_list(\"\", list(zip(positions, colors)))\n","\n","    if pv:\n","        # keep only the pvalues below the threshold\n","        df_values = df_values[df_values < threshold]\n","\n","    else:\n","        # keep only the correlations above the threshold\n","        df_values = df_values[df_values >= threshold]\n","\n","    # Plot the heatmap with the custom colormap\n","    fig, ax = plt.subplots(figsize=(20, 15))\n","    sns.heatmap(df_values, annot=True, cmap=cmap, vmin=0, vmax=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urAVb8JUJhNR"},"outputs":[],"source":["# calculate correlation matrix\n","corr = df[numerical_columns].corr()\n","our_heatmap(corr, False, 0.8)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":308},"executionInfo":{"elapsed":985032,"status":"ok","timestamp":1683542980865,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"gPPTmho9MHrj","outputId":"20b9db15-7ece-4116-d566-db67cc1f0590"},"outputs":[],"source":["# Bootstrap sampling to identify associations/correlations between categorical variables\n","\n","categorical_columns = ['SUBCAT_CD_EXT','MONTH','QUARTER','SEMESTER','YEAR','GENDER','SEG_LIFESTYLE_CD','SEG_LIFESTAGE_CD','CAT_CD_EXT', 'FAMILY_MEMBERS']\n","\n","df_200k = df[categorical_columns]\n","\n","# Create an empty matrix to store the p-values\n","pvals = np.zeros((len(df_200k.columns), len(df_200k.columns)))\n","\n","n_bootstraps = 1000\n","\n","pvals_ind = [None]*1000\n","\n","# Loop through all pairs of variables and calculate the p-value\n","for i, var1 in enumerate(df_200k.columns):\n","    for j, var2 in enumerate(df_200k.columns):\n","        if i == j:\n","            continue\n","        else:\n","            for k in range(0, n_bootstraps):\n","                sample = df_200k.sample(200, replace=True)\n","                cont_table = pd.crosstab(sample[var1], sample[var2])\n","                chi2, pval, dof, expected = chi2_contingency(cont_table)\n","                pvals_ind[k] = pval\n","        \n","            pvals[i, j] = np.mean(pvals_ind)\n","\n","# Convert the matrix to a data frame and print the results\n","pvals_df = pd.DataFrame(pvals, columns=df_200k.columns, index=df_200k.columns)\n","\n","pvals_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3207,"status":"ok","timestamp":1683543256674,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"V2URMWeN8hW5","outputId":"13b1952d-a1f8-4f1d-99c5-adb96856f4f0"},"outputs":[],"source":["our_heatmap(pvals_df)\n","our_heatmap(pvals_df, 0.05)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## One-hot Encoding"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1683754102921,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"9-KisaGe2XFo"},"outputs":[],"source":["df_sample = df_sample.drop(columns=['QUARTER','SEMESTER','SEG_LIFESTAGE_CD','SEG_LIFESTYLE_CD','MONTH', 'SUBCAT_CD_EXT'])"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683754102924,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"yxtfCt7t3FiY"},"outputs":[],"source":["# One-hot encoding categorical variables\n","df_sample = pd.get_dummies(df_sample, columns=['GENDER','FAMILY_MEMBERS','CAT_CD_EXT','YEAR'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qSmWT8Ts5VjK"},"source":["## Outlier detection (unsupervised learning) - No need to run"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1683754102926,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"Pz5_ld61RMRk"},"outputs":[],"source":["def plot_3d_clusters(df_clst, z_rot):\n","    # Compute the first three principal components of the data\n","    pca = PCA(n_components=3)\n","    principal_components = pca.fit_transform(df_clst)\n","\n","    # Create a scatter plot of the first three principal components, colored by cluster\n","    cluster_colors = np.array(['#de1c26', 'yellow', 'orange', 'red', 'purple', 'black', 'gray', 'magenta', '#84161a'])\n","    sns.set_style(\"ticks\", {\"axes.facecolor\": \"#ffffff\"})\n","    fig = plt.figure(figsize=(20, 15))\n","    ax = fig.add_subplot(111, projection='3d')\n","    ax.scatter(principal_components[:,0], principal_components[:,1], principal_components[:,2], c=cluster_colors[df_clst['cluster'].values % len(cluster_colors)], alpha=0.8)\n","    ax.scatter(principal_components[outliers_mask, 0], principal_components[outliers_mask, 1], principal_components[outliers_mask, 2], c='#84161a', marker='X', s=100, alpha=1.0)\n","    ax.view_init(elev=10, azim=z_rot)\n","    \n","    ax.set_xlabel('PC 1')\n","    ax.set_ylabel('PC 2')\n","    ax.set_zlabel('PC 3')\n","\n","    ax.w_xaxis.set_pane_color('#fcf2f2')  # Change x-axis color\n","    ax.w_yaxis.set_pane_color('#fcf2f2')  # Change y-axis color\n","    ax.w_zaxis.set_pane_color('#fcf2f2')  # Change z-axis color\n","\n","    \n","    ax.w_xaxis.set_ticklabels([])\n","    ax.w_yaxis.set_ticklabels([])\n","    ax.w_zaxis.set_ticklabels([])\n","    #ax.grid(False)\n","\n","    plt.show()\n","\n","\n","def plot_2d_clusters(df_clst):\n","    # Compute the first two principal components of the data\n","    pca = PCA(n_components=2)\n","    principal_components = pca.fit_transform(df_clst)\n","\n","    # Create a scatter plot of the first three principal components, colored by cluster\n","    cluster_colors = np.array(['#de1c26', 'yellow', 'orange', 'red', 'purple', 'black', 'gray', 'magenta', '#84161a'])\n","    sns.set_style(\"ticks\", {\"axes.facecolor\": \"#ffffff\"})\n","    fig = plt.figure(figsize=(15, 10))\n","    ax = fig.add_subplot(111)\n","    ax.scatter(principal_components[:,0], principal_components[:,1], c=cluster_colors[df_clst['cluster'].values % len(cluster_colors)], alpha=0.8)\n","    ax.scatter(principal_components[outliers_mask, 0], principal_components[outliers_mask, 1], c='#84161a', marker='X', s=100, alpha=1.0)\n","\n","    ax.set_facecolor('#fcf2f2')\n","    ax.set_xticklabels([])\n","    ax.set_yticklabels([])\n","    \n","    plt.xlabel('PC 1')\n","    plt.ylabel('PC 2')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":43336,"status":"ok","timestamp":1683754146248,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"EEkLZxGA5V1T","outputId":"ed213bd9-b0f1-418a-8bac-ce01a1c6e7ff"},"outputs":[],"source":["# Extract the numerical columns\n","df_200k_out = df_200k[numerical_columns]\n","\n","batch_size = 50000\n","\n","while len(df_200k_out) > batch_size:\n","    df_50k = df_200k_out.sample(batch_size, replace=False)\n","    # Perform DBSCAN clustering and obtain cluster labels\n","    dbscan = DBSCAN(eps=0.6, min_samples=800)\n","    labels = dbscan.fit_predict(df_50k)\n","\n","    # Identify the outliers\n","    outliers_mask = labels == -1\n","    outliers = df_50k[outliers_mask]\n","    df_200k_out = df_200k_out.drop(index=df_50k.index)\n","    df_200k = df_200k.drop(index=outliers.index)\n","\n","    print(\"Number of outliers:\", len(outliers))\n","\n","    # Add cluster labels to the original dataframe\n","    df_50k['cluster'] = labels\n","\n","\n","# Perform DBSCAN clustering and obtain cluster labels\n","dbscan = DBSCAN(eps=0.6, min_samples=800)\n","labels = dbscan.fit_predict(df_200k_out)\n","\n","# Identify the outliers\n","outliers_mask = labels == -1\n","outliers = df_200k_out[outliers_mask]\n","df_200k = df_200k.drop(index=outliers.index)\n","\n","print(\"Number of outliers:\", len(outliers))\n","\n","# Add cluster labels to the original dataframe\n","df_200k_out['cluster'] = labels\n","\n","plot_2d_clusters(df_200k_out)\n","\n","plot_3d_clusters(df_200k_out, 0)\n","plot_3d_clusters(df_200k_out, 90)\n","plot_3d_clusters(df_200k_out, 180)\n","plot_3d_clusters(df_200k_out, 270)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eIPUlj_0TaRC"},"source":["## Machine Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1683754146249,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"zRzAeb9STadN"},"outputs":[],"source":["def get_results(model, gs ,name, data, true_labels, target_names = ['No buy', 'Buy'], results=None, reasume=False):\n","    global param\n","    \n","    if hasattr(model, 'layers'):\n","        param = wtp_dnn_model.history.params\n","        best = np.mean(history.history['val_accuracy'])\n","        # predicted_labels_test = np.argmax(model.predict(data) , axis=-1)\n","        # print(f'This is Predicted_Labels_test in the first if :{predicted_labels_test}')\n","        predicted_labels = (model.predict_proba(data)[:,1] >= 0.5).astype(int)\n","        print(f'\\n\\nThis is Predicted_Labels in the first if:{predicted_labels}\\n\\n')\n","        im_model = InMemoryModel(model.predict, examples=data, target_names=target_names)\n","\n","    else:\n","        \n","        param = gs.best_params_\n","        best = gs.best_score_\n","        # predicted_labels_test = model.predict(data).ravel()\n","        # print(f'This is Predicted_Labels_test - else:{predicted_labels_test}')\n","        predicted_labels = (model.predict_proba(data)[:,1] >= 0.5).astype(int)\n","        print(f'\\n\\nThis is Predicted_Labels - else :{predicted_labels}\\n\\n')\n","\n","        if hasattr(model, 'predict_proba'):\n","            #predicted_probs = model.predict_proba(data)[:, 1]\n","            #print(f'This is the predict_proba results but the ones from the get_results function: {predicted_probs}')\n","            print('This model has a predict_proba method')\n","        elif hasattr(model, 'decision_function'):\n","            im_model = InMemoryModel(model.decision_function, examples=data, target_names=target_names)\n","        else: \n","            print('Cannot use InMemoryModel as predict_proba is not available')\n","           \n","        \n","    print('Mean Best Accuracy: {:2.2%}'.format(best))\n","    print('-'*60)\n","    print('Best Parameters:')\n","    print(param)\n","    print('-'*60)\n","    \n","    #y_pred = model.predict(data).ravel()\n","\n","    #y_predict_class = [1 if prob > 0.4 else 0 for prob in y_predict_prob_class_1]\n","\n","    # y_pred = (model.predict_proba(data)[:,1] >= 0.7).astype(bool)\n","\n","    y_pred = (model.predict_proba(data)[:,1] >= 0.5).astype(int).ravel()\n","    #y_pred = int(y_pred)\n","\n","    display_model_performance_metrics(true_labels, predicted_labels = predicted_labels, target_names = target_names)\n","    if len(target_names)==2:\n","        ras = roc_auc_score(y_true=true_labels, y_score=y_pred)\n","    else:\n","        roc_auc_multiclass, ras = roc_auc_score_multiclass(y_true=true_labels, y_score=y_pred, target_names=target_names)\n","        print('\\nROC AUC Score by Classes:\\n',roc_auc_multiclass)\n","        print('-'*60)\n","\n","    print('\\n\\n              ROC AUC Score: {:2.2%}'.format(ras))\n","    prob, score_roc, roc_auc = plot_model_roc_curve(model, data, true_labels, label_encoder=None, class_names=target_names)\n","    \n","    #interpreter = Interpretation(data, feature_names=cols)\n","    #plots = interpreter.feature_importance.plot_feature_importance(im_model, progressbar=False, n_jobs=1, ascending=True)\n","    \n","    r1 = pd.DataFrame([(prob, best, np.round(accuracy_score(true_labels, predicted_labels), 4), \n","                         ras, roc_auc)], index = [name],\n","                         columns = ['Prob', 'CV Accuracy', 'Accuracy', 'ROC AUC Score', 'ROC Area'])\n","    if reasume:\n","        results = r1\n","    elif (name in results.index):        \n","        results.loc[[name], :] = r1\n","    else: \n","        results = results.append(r1)\n","        \n","    return y_pred, results \n","\n","\n","def roc_auc_score_multiclass(y_true, y_score, target_names, average = \"macro\"):\n","\n","  #creating a set of all the unique classes using the actual class list\n","  unique_class = set(y_true)\n","  roc_auc_dict = {}\n","  mean_roc_auc = 0\n","  for per_class in unique_class:\n","    #creating a list of all the classes except the current class \n","    other_class = [x for x in unique_class if x != per_class]\n","\n","    #marking the current class as 1 and all other classes as 0\n","    new_y_true = [0 if x in other_class else 1 for x in y_true]\n","    new_y_score = [0 if x in other_class else 1 for x in y_score]\n","    num_new_y_true = sum(new_y_true)\n","\n","    #using the sklearn metrics method to calculate the roc_auc_score\n","    roc_auc = roc_auc_score(new_y_true, new_y_score, average = average)\n","    roc_auc_dict[target_names[per_class]] = np.round(roc_auc, 4)\n","    mean_roc_auc += num_new_y_true * np.round(roc_auc, 4)\n","    \n","  mean_roc_auc = mean_roc_auc/len(y_true)  \n","  return roc_auc_dict, mean_roc_auc\n","\n","def get_metrics(true_labels, predicted_labels):\n","    global accuracy\n","    global precision\n","    global recall\n","    global f1\n","    accuracy = metrics.accuracy_score(true_labels, predicted_labels)\n","    precision = metrics.precision_score(true_labels, predicted_labels)\n","    recall = metrics.recall_score(true_labels, predicted_labels)\n","    f1 = metrics.f1_score(true_labels, predicted_labels)\n","    \n","    print('Accuracy:  {:2.2%} '.format(accuracy))\n","    print('Precision: {:2.2%} '.format(precision))\n","    print('Recall:    {:2.2%} '.format(recall))\n","    print('F1 Score:  {:2.2%} '.format(f1))\n","    # #append results to arrays\n","    # np.append(accuracy_array, metrics.accuracy_score(true_labels, predicted_labels))\n","    # np.append(precision_array, metrics.precision_score(true_labels, predicted_labels, average='weighted'))\n","    # np.append(recall_array, metrics.recall_score(true_labels, predicted_labels, average='weighted'))\n","    # np.append(f1_array, metrics.f1_score(true_labels, predicted_labels, average='weighted'))\n","    \n","                        \n","\n","def train_predict_model(classifier,  train_features, train_labels,  test_features, test_labels):\n","    # build model    \n","    classifier.fit(train_features, train_labels)\n","    # predict using model\n","    predictions = classifier.predict(test_features) \n","    return predictions    \n","\n","\n","def display_confusion_matrix(true_labels, predicted_labels, target_names):\n","    \n","    total_classes = len(target_names)\n","    level_labels = [total_classes*[0], list(range(total_classes))]\n","\n","    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels)\n","    cm_frame = pd.DataFrame(data=cm, \n","                            columns=pd.MultiIndex(levels=[['Predicted:'], target_names], codes=level_labels), \n","                            index=pd.MultiIndex(levels=[['Actual:'], target_names], codes=level_labels)) \n","    print(cm_frame) \n","    \n","def display_classification_report(true_labels, predicted_labels, target_names):\n","\n","    report = metrics.classification_report(y_true=true_labels, y_pred=predicted_labels, target_names=target_names) \n","    print(report)\n","    \n","def display_model_performance_metrics(true_labels, predicted_labels, target_names):\n","    print('Model Performance metrics:')\n","    print('-'*30)\n","    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n","    print('\\nModel Classification report:')\n","    print('-'*30)\n","    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, target_names=target_names)\n","    print('\\nPrediction Confusion Matrix:')\n","    print('-'*30)\n","    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, target_names=target_names)\n","\n","def plot_model_roc_curve(clf, features, true_labels, label_encoder=None, class_names=None):\n","    \n","    ## Compute ROC curve and ROC area for each class\n","    fpr = dict()\n","    tpr = dict()\n","    roc_auc = dict()\n","    if hasattr(clf, 'classes_'):\n","        class_labels = clf.classes_\n","    elif label_encoder:\n","        class_labels = label_encoder.classes_\n","    elif class_names:\n","        class_labels = class_names\n","    else:\n","        raise ValueError('Unable to derive prediction classes, please specify class_names!')\n","    n_classes = len(class_labels)\n","   \n","    if n_classes == 2:\n","        if hasattr(clf, 'predict_proba'):\n","            prb = clf.predict_proba(features)\n","            if prb.shape[1] > 1:\n","                y_score = prb[:, prb.shape[1]-1] \n","            else:\n","                y_score = clf.predict(features).ravel()\n","            prob = True\n","        elif hasattr(clf, 'decision_function'):\n","            y_score = clf.decision_function(features)\n","            prob = False\n","        else:\n","            print(\"\\n\")\n","            #raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n","        \n","        fpr, tpr, _ = roc_curve(true_labels, y_score)      \n","        roc_auc = auc(fpr, tpr)\n","\n","        plt.plot(fpr, tpr, label='ROC curve (area = {0:3.2%})'.format(roc_auc), linewidth=2.5)\n","        \n","    elif n_classes > 2:\n","        if  hasattr(clf, 'clfs_'):\n","            y_labels = label_binarize(true_labels, classes=list(range(len(class_labels))))\n","        else:\n","            y_labels = label_binarize(true_labels, classes=class_labels)\n","        if hasattr(clf, 'predict_proba'):\n","            y_score = clf.predict_proba(features)\n","            prob = True\n","        elif hasattr(clf, 'decision_function'):\n","            y_score = clf.decision_function(features)\n","            prob = False\n","        else:\n","            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n","            \n","        for i in range(n_classes):\n","            fpr[i], tpr[i], _ = roc_curve(y_labels[:, i], y_score[:, i])\n","            roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","        ## Compute micro-average ROC curve and ROC area\n","        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_labels.ravel(), y_score.ravel())\n","        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","        ## Compute macro-average ROC curve and ROC area\n","        # First aggregate all false positive rates\n","        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","        # Then interpolate all ROC curves at this points\n","        mean_tpr = np.zeros_like(all_fpr)\n","        for i in range(n_classes):\n","            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n","        # Finally average it and compute AUC\n","        mean_tpr /= n_classes\n","        fpr[\"macro\"] = all_fpr\n","        tpr[\"macro\"] = mean_tpr\n","        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","        ## Plot ROC curves\n","        plt.figure(figsize=(12, 6))\n","        plt.plot(fpr[\"micro\"], tpr[\"micro\"], label='micro-average ROC curve (area = {0:2.2%})'\n","                       ''.format(roc_auc[\"micro\"]), linewidth=3)\n","\n","        plt.plot(fpr[\"macro\"], tpr[\"macro\"], label='macro-average ROC curve (area = {0:2.2%})'\n","                       ''.format(roc_auc[\"macro\"]), linewidth=3)\n","  \n","        for i, label in enumerate(class_names):\n","            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:2.2%})'\n","                                           ''.format(label, roc_auc[i]), linewidth=2, linestyle=':')\n","            \n","        roc_auc = roc_auc[\"macro\"]   \n","    else:\n","        raise ValueError('Number of classes should be atleast 2 or more')\n","        \n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([-0.01, 1.0])\n","    plt.ylim([0.0, 1.01])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend(loc=\"lower right\")\n","\n","    \n","    return prob, y_score, roc_auc"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1683754146250,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"crYEAm3FTafT"},"outputs":[],"source":["class select_fetaures(object):  # BaseEstimator, TransformerMixin,\n","     def __init__(self, select_cols):\n","         self.select_cols_ = select_cols\n","\n","     def fit(self, X, Y):\n","         pass\n","\n","     def transform(self, X):\n","         return X.loc[:, self.select_cols_]\n","\n","     def fit_transform(self, X, Y):\n","         self.fit(X, Y)\n","         df = self.transform(X)\n","         return df\n","\n","     def __getitem__(self, x):\n","         return self.X[x], self.Y[x]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":251,"status":"ok","timestamp":1683761567686,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"Ve5RdgiUTaiA"},"outputs":[],"source":["def LR(X_train, y_train, X_train_tune, y_train_tune, X_test, y_test):\n","        \n","    clf = Pipeline([\n","                # ('pca', PCA()),\n","                ('clf', LogisticRegression())])  \n","\n","    param_grid = {}\n","\n","    # Use SequentialFeatureSelector for forward/backward selection\n","    sfs_backward = SequentialFeatureSelector(clf, n_features_to_select='auto', tol=0.00, direction='forward', scoring='precision', cv=None, n_jobs=-1)  # Does 5-Fold CV\n","\n","    # Fit the feature selector to the training data\n","    sfs_backward.fit(X_train_tune, y_train_tune)\n","\n","    # Get the selected features and transform the data\n","    X_train = sfs_backward.transform(X_train)\n","    X_test = sfs_backward.transform(X_test)\n","\n","    global features_selected\n","    features_selected = sfs_backward.feature_names_in_[sfs_backward.support_]\n","\n","    print('Number of selected features: {}'.format(sfs_backward.n_features_to_select_))\n","    print('Features selected: {}'.format(sfs_backward.feature_names_in_[sfs_backward.support_]))\n","        \n","    gs = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='precision', cv=2, verbose=1, n_jobs=-1)\n","    LR = Pipeline([('gs', gs)]) \n","        \n","    LR.fit(X_train,y_train)\n","    \n","    #print the number of features used in the model\n","    #print('Number of features used: {}'.format(LR.named_steps['gs'].best_estimator_.named_steps['clf'].coef_.shape[1]))\n","\n","    joblib.dump(LR, 'LR.joblib')\n","\n","\n","    global y_proba\n","    y_proba = LR.predict_proba(X_test)\n","\n","    \n","\n","    y_pred, results = get_results(LR, gs ,'Logistic Regression', X_test, y_test, reasume=True)\n","    print(results)\n","    print(f'This is the predict_proba results {y_proba}')\n","\n","    return y_pred\n","        \n","\n","def RF(X_train, y_train, X_train_tune, y_train_tune, X_test, y_test):\n","\n","    clf = Pipeline([\n","                # ('pca', PCA()),\n","                ('clf', RandomForestClassifier())])  \n","\n","    param_grid = {'clf__criterion': ['gini']  # , 'entropy', 'log_loss'\n","                  ,'clf__n_estimators':  [500]       \n","                  ,'clf__min_samples_split': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n","                  ,'clf__max_depth': [10, 50, 100, 150, 200]\n","                  ,'clf__min_samples_leaf': [20, 40, 60, 80, 100]}\n","    \n","    # Use SequentialFeatureSelector for forward/backward selection\n","    sfs_backward = SequentialFeatureSelector(clf, n_features_to_select='auto', tol=0.00, direction='forward', scoring='recall', cv=None, n_jobs=-1)  # Does 5-Fold CV\n","\n","    # Fit the feature selector to the training data\n","    sfs_backward.fit(X_train_tune, y_train_tune)\n","\n","    global features_selected\n","    features_selected = sfs_backward.feature_names_in_[sfs_backward.support_]\n","\n","    # Get the selected features and transform the data\n","    X_train = sfs_backward.transform(X_train)\n","    X_test = sfs_backward.transform(X_test)\n","\n","    print('Number of selected features: {}'.format(sfs_backward.n_features_to_select_))\n","    print('Features selected: {}'.format(sfs_backward.feature_names_in_[sfs_backward.support_]))\n","\n","    gs = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='recall', cv=2, verbose=1, n_jobs=-1)\n","    RF = Pipeline([('gs', gs)]) \n","        \n","    RF.fit(X_train,y_train)\n","\n","    joblib.dump(RF, 'RF.joblib')\n","\n","\n","    global y_proba\n","    y_proba = RF.predict_proba(X_test)\n","\n","    y_pred, results = get_results(RF, gs ,'Random Forest', X_test, y_test, reasume=True)\n","    print(results)\n","    print(f'This is the predict_proba results {y_proba}')\n","\n","    return y_pred\n","\n","\n","def SVM(X_train, y_train, X_train_tuning, y_train_tuning, X_test, y_test):\n","\n","    clf = Pipeline([\n","                # ('pca', PCA()),\n","                ('clf', svm.SVC())])  \n","\n","    param_grid = {'clf__C': [0.05, 0.1, 0.15, 0.2]  # 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\n","                  ,'clf__kernel' : ['rbf']}   #, 'linear', , 'poly', 'linear', 'sigmoid', 'precomputed'\n","\n","    # Use SequentialFeatureSelector for backward selection\n","    sfs_backward = SequentialFeatureSelector(clf, n_features_to_select='auto', tol=0.05, direction='forward', scoring='f1', cv=None, n_jobs=-1)  # Does 5-Fold CV\n","\n","    # Fit the feature selector to the training data\n","    sfs_backward.fit(X_train_tuning, y_train_tuning)\n","\n","    # Get the selected features and transform the data\n","    X_train = sfs_backward.transform(X_train)\n","    X_test = sfs_backward.transform(X_test)\n","\n","    print('Number of selected features: {}'.format(sfs_backward.n_features_to_select_))\n","    print('Features selected: {}'.format(sfs_backward.feature_names_in_[sfs_backward.support_]))\n","        \n","    gs = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='f1', cv=5, verbose=1, n_jobs=-1)\n","    SVM = Pipeline([('gs', gs)]) \n","        \n","    SVM.fit(X_train,y_train)\n","\n","    results = get_results(SVM, gs ,'Support Vector Machines', X_test, y_test, reasume=True)\n","    print(results)\n","    \n","\n","def ANN(X_train, y_train, X_train_tune, y_train_tune, X_test, y_test):\n","    \n","    clf = Pipeline([\n","            # ('pca', PCA()),\n","            ('clf', MLPClassifier())])  \n","\n","    param_grid = {'clf__hidden_layer_sizes': [(64,), (128,), (256,)],\n","                  'clf__activation': ['relu'],\n","                  'clf__solver': ['adam'],\n","                  'clf__early_stopping': [True],  # creates a stratified validation set (10% of training data)\n","                  'clf__validation_fraction': [0.2], \n","                  'clf__n_iter_no_change': [10],\n","                  'clf__alpha': [0.0001, 0.001],\n","                  'clf__learning_rate': ['constant','invscaling','adaptive'],\n","                  'clf__tol': [0.0001, 0.001],\n","                  'clf__learning_rate_init': [0.0001, 0.001],\n","                  'clf__max_iter': [1000]}\n","\n","    # Use SequentialFeatureSelector for forward/backward selection\n","    sfs_backward = SequentialFeatureSelector(clf, n_features_to_select='auto', tol=0.00, direction='forward', scoring='f1', cv=None, n_jobs=-1)  # Does 5-Fold CV\n","\n","    # Fit the feature selector to the training data\n","    sfs_backward.fit(X_train_tune, y_train_tune)\n","\n","    # Get the selected features and transform the data\n","    X_train = sfs_backward.transform(X_train)\n","    X_test = sfs_backward.transform(X_test)\n","\n","    print('Number of selected features: {}'.format(sfs_backward.n_features_to_select_))\n","    print('Features selected: {}'.format(sfs_backward.feature_names_in_[sfs_backward.support_]))\n","\n","    gs = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='f1', cv=2, verbose=1, n_jobs=-1)\n","    ANN = Pipeline([('gs', gs)]) \n","        \n","    ANN.fit(X_train,y_train)\n","\n","    results = get_results(ANN, gs ,'Neural Network', X_test, y_test, reasume=True)\n","    print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":211,"status":"ok","timestamp":1683754243983,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"vD74h9UzTakT"},"outputs":[],"source":["def cv_12months(df_ML, model, resampling_tecnique):\n","    timestamps = df_ML['fulldate'].sort_values().unique()\n","    #display(timestamps.size)\n","\n","    # find the minimum timestamp\n","    min_timestamp = timestamps[0]\n","\n","    #store each of the metrics in an array for each one\n","    accuracy_array = np.array([])\n","    precision_array = np.array([])\n","    recall_array = np.array([])\n","    f1_array = np.array([])\n","\n","    \n","    probability_array = np.array([])\n","\n","    # full_xtest_df = []\n","\n","    df_total = pd.DataFrame()\n","\n","\n","    full_test_count = 0\n","    \n","\n","    \n","    # iterate over the timestamps and check if the time difference is less than 12 months\n","    for ts in timestamps[:-3]:\n","        \n","        if ts + 3 < timestamps.max():\n","            print(f'\\n\\nStart Iteration {ts}\\n\\n')\n","            if (ts - min_timestamp).n < 2: # 11\n","               \n","                print(f'Treino feito com os meses: {ts} até {ts+2}') # 11   \n","                train = df_ML[df_ML['fulldate'].isin([ts, ts+1, ts+2])]  # ts+3, ts+4, ts+5, ts+6, ts+7, ts+8, ts+9, ts+10, ts+11\n","                train_tune = train.groupby('fulldate').sample(frac=0.3, random_state=101)\n","                X_train_cv = train.drop(['TARGET','fulldate'], axis=1)\n","                y_train_cv = train['TARGET'].astype(int)\n","                X_train_tune = train_tune.drop(['TARGET','fulldate'], axis=1)\n","                y_train_tune = train_tune['TARGET'].astype(int)                \n","                \n","                X_train_cv, y_train_cv = resampling_tecnique(X_train_cv, y_train_cv)\n","                X_train_tune, y_train_tune = random_undersampling(X_train_tune, y_train_tune)\n","\n","                print('X_train_cv shape: ', X_train_cv.shape)\n","                print('X_train_tune shape: ', X_train_tune.shape)\n","            else:\n","               \n","                print(f'Treino feito com os meses: {ts} até {ts+2}') # 11\n","            \n","                train = df_ML[df_ML['fulldate'].isin([ts, ts+1, ts+2])]  # ts+3, ts+4, ts+5, ts+6, ts+7, ts+8, ts+9, ts+10, ts+11\n","                train_tune = train.groupby('fulldate').sample(frac=0.3, random_state=101)\n","                X_train_cv = train.drop(['TARGET','fulldate'], axis=1)\n","                y_train_cv = train['TARGET'].astype(int)\n","                X_train_tune = train_tune.drop(['TARGET','fulldate'], axis=1)\n","                y_train_tune = train_tune['TARGET'].astype(int) \n","\n","                X_train_cv, y_train_cv = resampling_tecnique(X_train_cv, y_train_cv)\n","                X_train_tune, y_train_tune = random_undersampling(X_train_tune, y_train_tune)\n","                \n","                print('X_train_cv shape: ', X_train_cv.shape)\n","                print('X_train_tune shape: ', X_train_tune.shape)\n","            \n","            print(f'Testado com mês: {ts+3}')\n","            test = df_ML[df_ML['fulldate'] == ts+3] # 12\n","            # print(f'Teste Fulldate: {test[\"fulldate\"].unique()}')\n","            # print(f'Ts: {ts+3}')\n","            X_test = test.drop(['TARGET', 'fulldate'], axis=1)\n","\n","            X_test_pandas = pd.DataFrame(X_test, columns=X_test.columns)\n","\n","            df_total = df_total.append(X_test_pandas)\n","            \n","\n","            # full_xtest_df = pd.concat(X_test)\n","\n","            full_test_count += X_test.shape[0]\n","\n","\n","            y_test = test['TARGET'].astype(int)\n","            print(f'X_test shape do mês {ts +3}: ', X_test.shape)\n","            #print(f'Teste feito com o mês: {ts+3}')  # 12\n","\n","            \n","            #print y_train_cv data type\n","            \n","            y_pred = model(X_train_cv, y_train_cv, X_train_tune, y_train_tune, X_test, y_test)\n","            # print(f'Treino feito com os meses: {ts} até {ts+2}') # 11\n","            # print(f'Teste feito com o mês: {ts+3}')  # 12\n","            # print('X_train_cv shape: ', X_train_cv.shape)\n","            # print('X_train_tune shape: ', X_train_tune.shape)\n","            # print(f'Y_pred shape: {y_pred.shape}')\n","            #append accuracy variable to the accuracy array\n","            accuracy_array = np.append(accuracy_array, accuracy)\n","            #append precision variable to the precision array\n","            precision_array = np.append(precision_array, precision)\n","            #append recall variable to the recall array\n","            recall_array = np.append(recall_array, recall)\n","            #append f1 variable to the f1 array\n","            f1_array = np.append(f1_array, f1)\n","            \n","            # Get the model exported in the last iteration of the model\n","            model.features = features_selected\n","            model.paramethers = param\n","            model_exported = model\n","\n","            \n","\n","\n","            probability_array = np.append(probability_array, y_proba)\n","            print('\\nEnd Iteration\\n')\n","            #pint barrier or * to separate the iterations\n","            print('******************************************************************************************')\n","        else: \n","            print(f'\\nFinish the for loop\\n')\n","            print(f'Accuracy Mean of all iterations : {np.mean(accuracy_array)}')\n","            print(f'Precision Mean of all iterations : {np.mean(precision_array)}')\n","            print(f'Recall Mean of all iterations: {np.mean(recall_array)}')\n","            print(f'F1 mean of all iterations: {np.mean(f1_array)}')\n","            return X_train_cv, y_train_cv,X_test, y_test , probability_array, df_total, y_pred, features_selected, param, model_exported\n","\n","    #print(f'\\n\\nNumber of test samples: {full_test_count}')\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#save model exported using joblib\n","def save_model(model, model_name):\n","    joblib.dump(model, model_name)\n","    print(f'\\nModel {model_name} saved successfully!')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1683754247606,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"kc-gKvzCTamG"},"outputs":[],"source":["def random_oversampling(x_train,y_train):\n","    ros = RandomOverSampler(random_state=101)\n","    X_train, y_train = ros.fit_resample(x_train, y_train)\n","    \n","    return X_train, y_train\n","\n","def roSMOTE(x_train,y_train):\n","    os = SMOTE(random_state=101)\n","    X_train, y_train = os.fit_resample(x_train, y_train)\n","    \n","    return X_train, y_train\n","\n","def random_undersampling(x_train,y_train):\n","    rus = RandomUnderSampler(random_state=101)\n","    X_train, y_train = rus.fit_resample(x_train, y_train)\n","    \n","    return X_train, y_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":616271,"status":"ok","timestamp":1683762644572,"user":{"displayName":"Luís Henriques","userId":"06170356873631694942"},"user_tz":-60},"id":"gAbCKTxnTap9","outputId":"a7099c1e-85e5-4a2b-9676-d317fac7e0fa"},"outputs":[],"source":["X_train_cv, y_train_cv,X_test, y_test , y_proba, df_total, y_pred, features_selected, param, model = cv_12months(df, LR, random_undersampling)   # Taking too long... What about removing all subcategory columns with all values 0?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features_selected"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Recommendation System - Top 20 Subcategories for each Customer in the month of November\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Normal recommendation with model ran above\n","\n","If you didn't run the model, ignore this. Run the sections below with the saved models."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#aggregate the results of y_proba in tuples of 2\n","y_proba = y_proba.reshape(int(y_proba.shape[0]/2), 2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_total['PROBABILITIES'] = y_proba.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def recommend_fixed():\n","    df_full = df.groupby('fulldate').sample(frac=0.2, random_state=101)\n","    df_nov = df_full[df_full['fulldate']=='2022-11']\n","    #reset index of df_200k_oct\n","    df_nov = df_nov.reset_index(drop=True)\n","    y_proba_last = y_proba[-y_pred.shape[0]:]\n","    y_proba_df = pd.DataFrame(y_proba_last, columns=['NO BUY', 'BUY'])\n","    y_pred_df = pd.DataFrame(y_pred, columns=['Target'])\n","    joined_prob_pred = y_pred_df.join(y_proba_df)\n","    df_oct_joined = df_nov.join(joined_prob_pred)\n","    df_oct_joined = df_oct_joined[['CUSTOMER_ACCOUNT_NR_MASK', 'SUBCAT_CD_EXT', 'SEG_LIFESTYLE_CD',  'NO BUY', 'BUY', 'Target']]\n","    #select only the rows where Target = 1\n","    df_oct_joined = df_oct_joined[df_oct_joined['Target'] == 1]\n","    #group by customer account nr mask and sort by buy\n","    recs_grouped = df_oct_joined.groupby('CUSTOMER_ACCOUNT_NR_MASK').apply(lambda x: x.sort_values(by='BUY', ascending=False))\n","    #rename CUSTOMER_ACCOUNT_NR_MASK to CUSTOMER\n","    recs_grouped = recs_grouped.rename(columns={'CUSTOMER_ACCOUNT_NR_MASK': 'CUSTOMER'})\n","    top_subcategories = recs_grouped.groupby('CUSTOMER_ACCOUNT_NR_MASK').apply(lambda x: x.nlargest(20, 'BUY'))\n","    \n","\n","    return recs_grouped, top_subcategories"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["recs_grouped, top_subcategories = recommend_fixed()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["recs_grouped"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Recommendations using .joblib file\n","\n","Independentemente do mês escolhido, as recomendações vão ser geradas com base nas features da última iteração do modelo"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def recommend_joblib(month, joblib_file):\n","\n","    df_full_job = df.groupby('fulldate').sample(frac=1, random_state=101)\n","    df_nov_job = df_full_job[df_full_job['fulldate']==month]\n","\n","    \n","    test_job = df_sample[df_sample['fulldate'] == month] \n","    X_test_job = test_job.drop(['TARGET', 'fulldate'], axis=1)\n","\n","    X_test_pandas_job = pd.DataFrame(X_test_job, columns=X_test_job.columns)\n","    model_job = joblib.load(joblib_file)\n","    X_test_deploy_job = X_test_pandas_job[['CUST_NUM_TRANSACTIONS_MONTH', 'CUST_NUM_TRANSACTIONS_QUARTER',\n","       'CUST_NUM_TRANSACTIONS_SEMESTER', 'CUST_NUM_TRANSACTIONS_YEAR',\n","       'CUST_TOTAL_QTY_BOUGHT_MONTH', 'CUST_TOTAL_QTY_BOUGHT_QUARTER',\n","       'CUST_TOTAL_QTY_BOUGHT_YEAR', 'CUST_NUM_UNIQUE_SUBCAT_SEMESTER',\n","       'CUST_NUM_UNIQUE_SUBCAT_YEAR',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_QUARTER',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_SEMESTER',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_YEAR',\n","       'CUST_AVG_BASKET_SIZE_SEMESTER', 'SUBCAT_NUM_TRANSACTIONS_YEAR',\n","       'SUBCAT_TOTAL_QTY_BOUGHT_QUARTER', 'SUBCAT_NUM_UNIQUE_CUST_MONTH',\n","       'CUSTSUBCAT_NUM_TRANSACTIONS_SEMESTER',\n","       'CUSTSUBCAT_TOTAL_QTY_BOUGHT_SEMESTER',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_QUARTER',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_SEMESTER',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_YEAR', 'GENDER_F', 'GENDER_M', 'FAMILY_MEMBERS_(0, 0)',\n","       'FAMILY_MEMBERS_(1, 2)', 'FAMILY_MEMBERS_(3, 8)', 'CAT_CD_EXT_101',\n","       'CAT_CD_EXT_102', 'CAT_CD_EXT_103', 'CAT_CD_EXT_202', 'CAT_CD_EXT_203',\n","       'CAT_CD_EXT_302', 'CAT_CD_EXT_303', 'CAT_CD_EXT_304', 'CAT_CD_EXT_502',\n","       'CAT_CD_EXT_503', 'CAT_CD_EXT_504', 'CAT_CD_EXT_601', 'CAT_CD_EXT_603',\n","       'CAT_CD_EXT_604', 'CAT_CD_EXT_702', 'CAT_CD_EXT_801', 'CAT_CD_EXT_804',\n","       'CAT_CD_EXT_902', 'CAT_CD_EXT_1001', 'CAT_CD_EXT_1002',\n","       'CAT_CD_EXT_1402', 'CAT_CD_EXT_1403', 'CAT_CD_EXT_1701',\n","       'CAT_CD_EXT_1703', 'YEAR_2021', 'YEAR_2022']]\n","    y_proba_job = model_job.predict_proba(X_test_deploy_job)\n","    y_pred_job = model_job.predict(X_test_deploy_job)\n","    X_test_pandas_job['PROBABILITIES'] = y_proba_job.tolist()\n","   \n","    #reset index of df_200k_oct\n","    df_nov_job = df_nov_job.reset_index(drop=True)\n","    y_proba_last = y_proba_job[-y_pred_job.shape[0]:]\n","    y_proba_df = pd.DataFrame(y_proba_last, columns=['NO BUY', 'BUY'])\n","    y_pred_df = pd.DataFrame(y_pred_job, columns=['Target'])\n","    joined_prob_pred = y_pred_df.join(y_proba_df)\n","    df_oct_joined = df_nov_job.join(joined_prob_pred)\n","    df_oct_joined = df_oct_joined[['CUSTOMER_ACCOUNT_NR_MASK', 'SUBCAT_CD_EXT', 'SEG_LIFESTYLE_CD',  'NO BUY', 'BUY', 'Target']]\n","    #select only the rows where Target = 1\n","    df_oct_joined = df_oct_joined[df_oct_joined['Target'] == 1]\n","    #group by customer account nr mask and sort by buy\n","    recs_grouped = df_oct_joined.groupby('CUSTOMER_ACCOUNT_NR_MASK').apply(lambda x: x.sort_values(by='BUY', ascending=False))\n","    #rename CUSTOMER_ACCOUNT_NR_MASK to CUSTOMER\n","    recs_grouped_job = recs_grouped.rename(columns={'CUSTOMER_ACCOUNT_NR_MASK': 'CUSTOMER'})\n","    top20_subcategories_job = recs_grouped_job.groupby('CUSTOMER_ACCOUNT_NR_MASK').apply(lambda x: x.nlargest(20, 'BUY'))\n","    \n","\n","    return df_oct_joined, y_pred_job, recs_grouped_job, top20_subcategories_job\n","\n","\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df_oct_joined, y_pred_job, recs_grouped_job, top20_subcategories_job = recommend_joblib('2022-11', 'RF.joblib')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Calculation of frequencies for subcategories (recommendations and total dataset)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["##########é para copiar la p baixo\n","\n","df_sample2 = df.groupby('fulldate').sample(frac=1, random_state=101)\n","\n","#drop customer id column because we want to generalize the model, instead of trying to predict for each customer\n","df_sample2 = df_sample2.drop(columns=['CUSTOMER_ACCOUNT_NR_MASK','REG_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH'])\n","\n","#df_500k.value_counts('fulldate').sort_index()\n","\n","# Function to replace outliers with average value of the column\n","def replace_outliers_with_average(df_non_minmax, column):\n","    # Calculate the lower and upper bounds for outliers using the boxplot rule\n","    q1 = df_non_minmax[column].quantile(0.25)\n","    q3 = df_non_minmax[column].quantile(0.75)\n","    iqr = q3 - q1\n","    lower_bound = q1 - 1.5 * iqr\n","    upper_bound = q3 + 1.5 * iqr\n","    \n","    # Replace outliers with the average value of the column\n","    avg_value = df_non_minmax[column].mean()\n","    df_non_minmax[column] = df_non_minmax[column].apply(lambda x: avg_value if x < lower_bound or x > upper_bound else x)\n","    \n","    return df_non_minmax\n","\n","# Detect outliers and replace them with average for each column in 'columns_to_check'\n","numerical_columns = ['CUST_NUM_TRANSACTIONS_MONTH', 'CUST_NUM_TRANSACTIONS_QUARTER',\n","       'CUST_NUM_TRANSACTIONS_SEMESTER', 'CUST_NUM_TRANSACTIONS_YEAR',\n","       'CUST_TOTAL_QTY_BOUGHT_MONTH', 'CUST_TOTAL_QTY_BOUGHT_QUARTER',\n","       'CUST_TOTAL_QTY_BOUGHT_SEMESTER', 'CUST_TOTAL_QTY_BOUGHT_YEAR',\n","       'CUST_NUM_UNIQUE_SUBCAT_MONTH', 'CUST_NUM_UNIQUE_SUBCAT_QUARTER',\n","       'CUST_NUM_UNIQUE_SUBCAT_SEMESTER', 'CUST_NUM_UNIQUE_SUBCAT_YEAR',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_QUARTER',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_SEMESTER',\n","       'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION_YEAR',\n","       'CUST_AVG_BASKET_SIZE_MONTH', 'CUST_AVG_BASKET_SIZE_QUARTER',\n","       'CUST_AVG_BASKET_SIZE_SEMESTER', 'CUST_AVG_BASKET_SIZE_YEAR',\n","       'SUBCAT_NUM_TRANSACTIONS_MONTH', 'SUBCAT_NUM_TRANSACTIONS_QUARTER',\n","       'SUBCAT_NUM_TRANSACTIONS_SEMESTER', 'SUBCAT_NUM_TRANSACTIONS_YEAR',\n","       'SUBCAT_TOTAL_QTY_BOUGHT_MONTH', 'SUBCAT_TOTAL_QTY_BOUGHT_QUARTER',\n","       'SUBCAT_TOTAL_QTY_BOUGHT_SEMESTER', 'SUBCAT_TOTAL_QTY_BOUGHT_YEAR',\n","       'SUBCAT_NUM_UNIQUE_CUST_MONTH', 'SUBCAT_NUM_UNIQUE_CUST_QUARTER',\n","       'SUBCAT_NUM_UNIQUE_CUST_SEMESTER', 'SUBCAT_NUM_UNIQUE_CUST_YEAR',\n","       'CUSTSUBCAT_NUM_TRANSACTIONS_MONTH',\n","       'CUSTSUBCAT_NUM_TRANSACTIONS_QUARTER',\n","       'CUSTSUBCAT_NUM_TRANSACTIONS_SEMESTER',\n","       'CUSTSUBCAT_NUM_TRANSACTIONS_YEAR', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT_MONTH',\n","       'CUSTSUBCAT_TOTAL_QTY_BOUGHT_QUARTER',\n","       'CUSTSUBCAT_TOTAL_QTY_BOUGHT_SEMESTER',\n","       'CUSTSUBCAT_TOTAL_QTY_BOUGHT_YEAR',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_MONTH',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_QUARTER',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_SEMESTER',\n","       'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION_YEAR']\n","\n","for column in numerical_columns:\n","    df_sample2 = replace_outliers_with_average(df_sample2, column)\n","    \n","df_sample2.shape\n","\n","\n","scaler = MinMaxScaler()\n","df_sample2[numerical_columns] = scaler.fit_transform(df_sample2[numerical_columns])\n","\n","df_sample2 = df_sample2.drop(columns=['QUARTER','SEMESTER','MONTH'])\n","\n","# One-hot encoding categorical variables\n","df_sample2 = pd.get_dummies(df_sample2, columns=['GENDER','FAMILY_MEMBERS','YEAR'])\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#select only rows where TARGET is equal to 1\n","df_only_1s = df_sample2[df_sample2['TARGET'] == 1]\n","#show most frequent SUBCAT_CD_EXT for each SEG_LIFESTYLE_CD\n","lifestyles_w_subcat = pd.DataFrame(df_only_1s.groupby('SEG_LIFESTYLE_CD')['SUBCAT_CD_EXT'].value_counts())\n","\n","#instead of using the absolute number, use the percentage of each SUBCAT_CD_EXT for each SEG_LIFESTYLE_CD\n","lifestyles_w_subcat['PERC_TOTAL'] = lifestyles_w_subcat.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n","\n","#rename the column SUBCAT_CD_EXT to FREQ_TOTAL\n","lifestyles_w_subcat.rename(columns={'SUBCAT_CD_EXT': 'FREQ_TOTAL'}, inplace=True)\n","\n","#make a copy of lifestyles_w_subcat\n","lifestyles_w_subcat_copy = lifestyles_w_subcat.copy()\n","\n","#reset the index\n","lifestyles_w_subcat.reset_index(inplace=True)\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CUSTOMER</th>\n","      <th>SEG_LIFESTYLE_CD</th>\n","      <th>SUBCAT_CD_EXT</th>\n","      <th>FREQ_RECS</th>\n","      <th>FREQ_TOTAL</th>\n","      <th>PERC_RECS</th>\n","      <th>PERC_TOTAL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>44977</th>\n","      <td>58149188</td>\n","      <td>4</td>\n","      <td>10102</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>5.00</td>\n","      <td>3.41</td>\n","    </tr>\n","    <tr>\n","      <th>44978</th>\n","      <td>58156989</td>\n","      <td>4</td>\n","      <td>10102</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>5.00</td>\n","      <td>3.41</td>\n","    </tr>\n","    <tr>\n","      <th>44984</th>\n","      <td>58156989</td>\n","      <td>4</td>\n","      <td>100204</td>\n","      <td>2</td>\n","      <td>31</td>\n","      <td>5.00</td>\n","      <td>3.30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       CUSTOMER  SEG_LIFESTYLE_CD  SUBCAT_CD_EXT  FREQ_RECS  FREQ_TOTAL  \\\n","44977  58149188                 4          10102          2          32   \n","44978  58156989                 4          10102          2          32   \n","44984  58156989                 4         100204          2          31   \n","\n","       PERC_RECS  PERC_TOTAL  \n","44977       5.00        3.41  \n","44978       5.00        3.41  \n","44984       5.00        3.30  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["freq_customer = recs_grouped_job['CUSTOMER'].value_counts().idxmax()\n","\n","recs_for_freqc = recs_grouped_job[recs_grouped_job['CUSTOMER'] == freq_customer]\n","\n","#show the most frequent subcategories for each unique SEG_LIFESTYLE_CD\n","freq_subcats = pd.DataFrame(top20_subcategories_job.groupby('SEG_LIFESTYLE_CD')['SUBCAT_CD_EXT'].value_counts())\n","pd.set_option('display.max_rows', None)\n","#rename SUBCAT_CD_EXT to FREQUENCY\n","freq_subcats = freq_subcats.rename(columns={'SUBCAT_CD_EXT': 'FREQUENCY'})\n","#create new column with percentage of each subcategory\n","freq_subcats['PERCENTAGE'] = freq_subcats.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n","\n","#reset index from teste\n","teste_reseted = freq_subcats.reset_index()\n","\n","#join teste_reseted with recs_for_freqc on SEG_LIFESTYLE_CD and SUBCAT_CD_EXT\n","joined_both = teste_reseted.merge(recs_grouped_job, on=['SEG_LIFESTYLE_CD', 'SUBCAT_CD_EXT'])\n","\n","#rename frequency to freq_recs and percentage to perc_recs\n","joined_both = joined_both.rename(columns={'FREQUENCY': 'FREQ_RECS', 'PERCENTAGE': 'PERC_RECS'})\n","\n","#join joined_both with lifestyles_w_subcat on SEG_LIFESTYLE_CD and SUBCAT_CD_EXT\n","joined_wo_dsc = joined_both.merge(lifestyles_w_subcat, on=['SEG_LIFESTYLE_CD', 'SUBCAT_CD_EXT'])\n","\n","ordenar_colunas = ['CUSTOMER', 'SEG_LIFESTYLE_CD', 'SUBCAT_CD_EXT', 'FREQ_RECS', 'FREQ_TOTAL', 'PERC_RECS', 'PERC_TOTAL'] \n","\n","joined_wo_dsc = joined_wo_dsc[ordenar_colunas]\n","\n","#order by perc_total\n","joined_wo_dsc = joined_wo_dsc.sort_values(by=['PERC_TOTAL'], ascending=False)\n","\n","joined_wo_dsc.head(3)\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>CUSTOMER</th>\n","      <th>SUBCAT_CD_EXT</th>\n","      <th>SEG_LIFESTYLE_CD</th>\n","      <th>NO BUY</th>\n","      <th>BUY</th>\n","      <th>Target</th>\n","    </tr>\n","    <tr>\n","      <th>CUSTOMER_ACCOUNT_NR_MASK</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">19342312</th>\n","      <th>55984</th>\n","      <td>19342312</td>\n","      <td>10101</td>\n","      <td>2</td>\n","      <td>0.07</td>\n","      <td>0.93</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>122630</th>\n","      <td>19342312</td>\n","      <td>100204</td>\n","      <td>2</td>\n","      <td>0.07</td>\n","      <td>0.93</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>22929</th>\n","      <td>19342312</td>\n","      <td>20201</td>\n","      <td>2</td>\n","      <td>0.07</td>\n","      <td>0.93</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>25228</th>\n","      <td>19342312</td>\n","      <td>20301</td>\n","      <td>2</td>\n","      <td>0.07</td>\n","      <td>0.93</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>54367</th>\n","      <td>19342312</td>\n","      <td>60401</td>\n","      <td>2</td>\n","      <td>0.07</td>\n","      <td>0.93</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                 CUSTOMER  SUBCAT_CD_EXT  SEG_LIFESTYLE_CD  \\\n","CUSTOMER_ACCOUNT_NR_MASK                                                     \n","19342312                 55984   19342312          10101                 2   \n","                         122630  19342312         100204                 2   \n","                         22929   19342312          20201                 2   \n","                         25228   19342312          20301                 2   \n","                         54367   19342312          60401                 2   \n","\n","                                 NO BUY  BUY  Target  \n","CUSTOMER_ACCOUNT_NR_MASK                              \n","19342312                 55984     0.07 0.93       1  \n","                         122630    0.07 0.93       1  \n","                         22929     0.07 0.93       1  \n","                         25228     0.07 0.93       1  \n","                         54367     0.07 0.93       1  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["recs_for_freqc.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Compare entire dataframe with recommendations by Lifestage Segment"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["def lifestage_comparison():\n","    #from def_oct_joined group by seg_lifestyle_cd and sort by buy\n","    df_nov_joined = df_oct_joined.groupby('SEG_LIFESTYLE_CD').apply(lambda x: x.sort_values(by='BUY', ascending=False))\n","\n","    #rename SEG_LIFESTYLE_CD to LYFESTYLE_SEGMENT\n","    df_nov_joined = df_nov_joined.rename(columns={'SEG_LIFESTYLE_CD': 'LYFESTYLE_SEGMENT'})\n","\n","    #select 20 rows from every group\n","    topmais = df_nov_joined.groupby('SEG_LIFESTYLE_CD').apply(lambda x: x.nlargest(20, 'BUY'))\n","    #show the most frequent subcategories for each unique SEG_LIFESTYLE_CD\n","    freq_subcats2 = pd.DataFrame(top20_subcategories_job.groupby('SEG_LIFESTYLE_CD')['SUBCAT_CD_EXT'].value_counts())\n","    pd.set_option('display.max_rows', None)\n","    #rename SUBCAT_CD_EXT to FREQUENCY\n","    freq_subcats2 = freq_subcats2.rename(columns={'SUBCAT_CD_EXT': 'FREQUENCY'})\n","    #create new column with percentage of each subcategory\n","    freq_subcats2['PERCENTAGE'] = freq_subcats2.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n","\n","    topmais_drop = topmais.reset_index(level=1, drop=True)\n","\n","    #show the most frequent subcategories for each unique SEG_LIFESTYLE_CD\n","    freq_subcats2 = pd.DataFrame(top20_subcategories_job.groupby('SEG_LIFESTYLE_CD')['SUBCAT_CD_EXT'].value_counts())\n","    pd.set_option('display.max_rows', None)\n","    #rename SUBCAT_CD_EXT to FREQUENCY\n","    freq_subcats2 = freq_subcats2.rename(columns={'SUBCAT_CD_EXT': 'FREQUENCY'})\n","    #create new column with percentage of each subcategory\n","    freq_subcats2['PERCENTAGE'] = freq_subcats2.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n","\n","    #reset index from teste\n","    teste_reseted2 = freq_subcats2.reset_index()\n","\n","    #join teste_reseted with recs_for_freqc on SEG_LIFESTYLE_CD and SUBCAT_CD_EXT\n","    joined_both2 = teste_reseted2.merge(topmais_drop, on=['SEG_LIFESTYLE_CD', 'SUBCAT_CD_EXT'])\n","\n","    #rename frequency to freq_recs and percentage to perc_recs\n","    joined_both2 = joined_both2.rename(columns={'FREQUENCY': 'FREQ_RECS', 'PERCENTAGE': 'PERC_RECS'})\n","\n","    #join joined_both with lifestyles_w_subcat on SEG_LIFESTYLE_CD and SUBCAT_CD_EXT\n","    joined_wo_dsc2 = joined_both2.merge(lifestyles_w_subcat, on=['SEG_LIFESTYLE_CD', 'SUBCAT_CD_EXT'])\n","\n","    ordenar_colunas = ['SEG_LIFESTYLE_CD', 'SUBCAT_CD_EXT', 'FREQ_RECS', 'FREQ_TOTAL', 'PERC_RECS', 'PERC_TOTAL'] \n","\n","    joined_wo_dsc2 = joined_wo_dsc2[ordenar_colunas]\n","\n","    #group by seg_lifestyle_cd\n","    joined_wo_dsc2 = joined_wo_dsc2.groupby('SEG_LIFESTYLE_CD').apply(lambda x: x.sort_values(by='PERC_TOTAL', ascending=False))\n","\n","    #rename column name SEG_LIFESTYLE_CD to LIFESTYLE_SEGMENT\n","    joined_wo_dsc2 = joined_wo_dsc2.rename(columns={'SEG_LIFESTYLE_CD': 'LIFESTYLE_SEGMENT'})\n","\n","    #order by perc_total\n","    joined_wo_dsc2 = joined_wo_dsc2.sort_values(by=['PERC_TOTAL'], ascending=False)\n","\n","    #order index SEG_LIFESTYLE_CD descending\n","    joined_wo_dsc2 = joined_wo_dsc2.sort_index(ascending=True)\n","\n","    #drop duplicates from joined_wo_dsc2\n","    joined_wo_dsc2 = joined_wo_dsc2.drop_duplicates(subset=['LIFESTYLE_SEGMENT', 'SUBCAT_CD_EXT'], keep='first')\n","\n","    #drop column LIFESTYLE_SEGMENT\n","    joined_wo_dsc2 = joined_wo_dsc2.drop(columns=['LIFESTYLE_SEGMENT'])\n","\n","    return joined_wo_dsc2\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["ls_comparison = lifestage_comparison()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>SUBCAT_CD_EXT</th>\n","      <th>FREQ_RECS</th>\n","      <th>FREQ_TOTAL</th>\n","      <th>PERC_RECS</th>\n","      <th>PERC_TOTAL</th>\n","    </tr>\n","    <tr>\n","      <th>SEG_LIFESTYLE_CD</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">1</th>\n","      <th>0</th>\n","      <td>30401</td>\n","      <td>288</td>\n","      <td>5193</td>\n","      <td>3.28</td>\n","      <td>2.37</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>100201</td>\n","      <td>261</td>\n","      <td>4063</td>\n","      <td>2.97</td>\n","      <td>1.85</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>140304</td>\n","      <td>242</td>\n","      <td>4217</td>\n","      <td>2.76</td>\n","      <td>1.92</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">2</th>\n","      <th>20</th>\n","      <td>30401</td>\n","      <td>213</td>\n","      <td>3917</td>\n","      <td>3.50</td>\n","      <td>2.52</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>10101</td>\n","      <td>212</td>\n","      <td>3790</td>\n","      <td>3.49</td>\n","      <td>2.44</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>20302</td>\n","      <td>211</td>\n","      <td>3286</td>\n","      <td>3.47</td>\n","      <td>2.11</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">3</th>\n","      <th>40</th>\n","      <td>10101</td>\n","      <td>149</td>\n","      <td>2531</td>\n","      <td>4.06</td>\n","      <td>2.71</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>20302</td>\n","      <td>122</td>\n","      <td>2072</td>\n","      <td>3.32</td>\n","      <td>2.22</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>80103</td>\n","      <td>115</td>\n","      <td>1964</td>\n","      <td>3.13</td>\n","      <td>2.11</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">4</th>\n","      <th>60</th>\n","      <td>10102</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>5.00</td>\n","      <td>3.41</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>10303</td>\n","      <td>2</td>\n","      <td>22</td>\n","      <td>5.00</td>\n","      <td>2.34</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>100204</td>\n","      <td>2</td>\n","      <td>31</td>\n","      <td>5.00</td>\n","      <td>3.30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     SUBCAT_CD_EXT  FREQ_RECS  FREQ_TOTAL  PERC_RECS  \\\n","SEG_LIFESTYLE_CD                                                       \n","1                0           30401        288        5193       3.28   \n","                 6          100201        261        4063       2.97   \n","                 7          140304        242        4217       2.76   \n","2                20          30401        213        3917       3.50   \n","                 25          10101        212        3790       3.49   \n","                 27          20302        211        3286       3.47   \n","3                40          10101        149        2531       4.06   \n","                 42          20302        122        2072       3.32   \n","                 45          80103        115        1964       3.13   \n","4                60          10102          2          32       5.00   \n","                 61          10303          2          22       5.00   \n","                 62         100204          2          31       5.00   \n","\n","                     PERC_TOTAL  \n","SEG_LIFESTYLE_CD                 \n","1                0         2.37  \n","                 6         1.85  \n","                 7         1.92  \n","2                20        2.52  \n","                 25        2.44  \n","                 27        2.11  \n","3                40        2.71  \n","                 42        2.22  \n","                 45        2.11  \n","4                60        3.41  \n","                 61        2.34  \n","                 62        3.30  "]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["ls_comparison.groupby('SEG_LIFESTYLE_CD').head(3)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Deployment\n","\n","December 2022 does not have the TARGET value. Using the best model/setup used for training, the TARGET value is predicted\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["X_test_deploy = df_sample[df_sample['fulldate'] == '2022-12']\n","X_test_deploy = X_test_deploy.drop(columns=['TARGET', 'fulldate'])\n","#from df_sample print number of rows with fulldate = '2022-12' \n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["df_oct_joined, y_pred_job, recs_grouped_job, top20_subcategories_job_deploy = recommend_joblib('2022-12', 'RF.joblib')"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["y_pred_job.shape[0] == X_test_deploy.shape[0]"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def compare_customer():\n","    freq_customer = recs_grouped_job['CUSTOMER'].value_counts().idxmax()\n","\n","    recs_for_freqc = recs_grouped_job[recs_grouped_job['CUSTOMER'] == freq_customer]\n","\n","    #show the most frequent subcategories for each unique SEG_LIFESTYLE_CD\n","    freq_subcats = pd.DataFrame(top20_subcategories_job_deploy.groupby('SEG_LIFESTYLE_CD')['SUBCAT_CD_EXT'].value_counts())\n","    pd.set_option('display.max_rows', None)\n","    #rename SUBCAT_CD_EXT to FREQUENCY\n","    freq_subcats = freq_subcats.rename(columns={'SUBCAT_CD_EXT': 'FREQUENCY'})\n","    #create new column with percentage of each subcategory\n","    freq_subcats['PERCENTAGE'] = freq_subcats.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n","\n","    #reset index from teste\n","    teste_reseted = freq_subcats.reset_index()\n","\n","    #join teste_reseted with recs_for_freqc on SEG_LIFESTYLE_CD and SUBCAT_CD_EXT\n","    joined_both = teste_reseted.merge(recs_for_freqc, on=['SEG_LIFESTYLE_CD', 'SUBCAT_CD_EXT'])\n","\n","    #rename frequency to freq_recs and percentage to perc_recs\n","    joined_both = joined_both.rename(columns={'FREQUENCY': 'FREQ_RECS', 'PERCENTAGE': 'PERC_RECS'})\n","\n","    #join joined_both with lifestyles_w_subcat on SEG_LIFESTYLE_CD and SUBCAT_CD_EXT\n","    joined_wo_dsc = joined_both.merge(lifestyles_w_subcat, on=['SEG_LIFESTYLE_CD', 'SUBCAT_CD_EXT'])\n","\n","    ordenar_colunas = ['CUSTOMER', 'SEG_LIFESTYLE_CD', 'SUBCAT_CD_EXT', 'FREQ_RECS', 'FREQ_TOTAL', 'PERC_RECS', 'PERC_TOTAL'] \n","\n","    customer = joined_wo_dsc[ordenar_colunas]\n","\n","    \n","\n","    #in the customer df, creates a column with the difference between perc_total and perc_recs\n","    customer['DIFFERENCE_PERC'] = customer['PERC_RECS'] - customer['PERC_TOTAL']\n","\n","    #order customer by perc_total\n","    customer = customer.sort_values(by=['DIFFERENCE_PERC'], ascending=False)\n","\n","    return customer\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["customer = compare_customer()"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CUSTOMER</th>\n","      <th>SEG_LIFESTYLE_CD</th>\n","      <th>SUBCAT_CD_EXT</th>\n","      <th>FREQ_RECS</th>\n","      <th>FREQ_TOTAL</th>\n","      <th>PERC_RECS</th>\n","      <th>PERC_TOTAL</th>\n","      <th>DIFFERENCE_PERC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>20201</td>\n","      <td>286</td>\n","      <td>4377</td>\n","      <td>3.24</td>\n","      <td>2.00</td>\n","      <td>1.24</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>100201</td>\n","      <td>253</td>\n","      <td>4063</td>\n","      <td>2.86</td>\n","      <td>1.85</td>\n","      <td>1.01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>10301</td>\n","      <td>266</td>\n","      <td>4432</td>\n","      <td>3.01</td>\n","      <td>2.02</td>\n","      <td>0.99</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>10303</td>\n","      <td>265</td>\n","      <td>4442</td>\n","      <td>3.00</td>\n","      <td>2.03</td>\n","      <td>0.97</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>80110</td>\n","      <td>228</td>\n","      <td>3581</td>\n","      <td>2.58</td>\n","      <td>1.63</td>\n","      <td>0.95</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>20302</td>\n","      <td>224</td>\n","      <td>3598</td>\n","      <td>2.54</td>\n","      <td>1.64</td>\n","      <td>0.89</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>10101</td>\n","      <td>282</td>\n","      <td>5133</td>\n","      <td>3.19</td>\n","      <td>2.34</td>\n","      <td>0.85</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>10102</td>\n","      <td>221</td>\n","      <td>3660</td>\n","      <td>2.50</td>\n","      <td>1.67</td>\n","      <td>0.83</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>100204</td>\n","      <td>272</td>\n","      <td>5024</td>\n","      <td>3.08</td>\n","      <td>2.29</td>\n","      <td>0.79</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>60401</td>\n","      <td>243</td>\n","      <td>4338</td>\n","      <td>2.75</td>\n","      <td>1.98</td>\n","      <td>0.77</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>20204</td>\n","      <td>182</td>\n","      <td>2947</td>\n","      <td>2.06</td>\n","      <td>1.34</td>\n","      <td>0.72</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>80103</td>\n","      <td>176</td>\n","      <td>2883</td>\n","      <td>1.99</td>\n","      <td>1.32</td>\n","      <td>0.68</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>20306</td>\n","      <td>218</td>\n","      <td>4025</td>\n","      <td>2.47</td>\n","      <td>1.84</td>\n","      <td>0.63</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>10201</td>\n","      <td>176</td>\n","      <td>3093</td>\n","      <td>1.99</td>\n","      <td>1.41</td>\n","      <td>0.58</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>10205</td>\n","      <td>195</td>\n","      <td>3573</td>\n","      <td>2.21</td>\n","      <td>1.63</td>\n","      <td>0.58</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>30401</td>\n","      <td>260</td>\n","      <td>5193</td>\n","      <td>2.94</td>\n","      <td>2.37</td>\n","      <td>0.57</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>30201</td>\n","      <td>177</td>\n","      <td>3144</td>\n","      <td>2.00</td>\n","      <td>1.43</td>\n","      <td>0.57</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>80411</td>\n","      <td>140</td>\n","      <td>2700</td>\n","      <td>1.58</td>\n","      <td>1.23</td>\n","      <td>0.35</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>140204</td>\n","      <td>88</td>\n","      <td>1413</td>\n","      <td>1.00</td>\n","      <td>0.64</td>\n","      <td>0.35</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>13031606</td>\n","      <td>1</td>\n","      <td>30202</td>\n","      <td>118</td>\n","      <td>2190</td>\n","      <td>1.34</td>\n","      <td>1.00</td>\n","      <td>0.34</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    CUSTOMER  SEG_LIFESTYLE_CD  SUBCAT_CD_EXT  FREQ_RECS  FREQ_TOTAL  \\\n","0   13031606                 1          20201        286        4377   \n","6   13031606                 1         100201        253        4063   \n","3   13031606                 1          10301        266        4432   \n","4   13031606                 1          10303        265        4442   \n","8   13031606                 1          80110        228        3581   \n","9   13031606                 1          20302        224        3598   \n","1   13031606                 1          10101        282        5133   \n","10  13031606                 1          10102        221        3660   \n","2   13031606                 1         100204        272        5024   \n","7   13031606                 1          60401        243        4338   \n","13  13031606                 1          20204        182        2947   \n","16  13031606                 1          80103        176        2883   \n","11  13031606                 1          20306        218        4025   \n","15  13031606                 1          10201        176        3093   \n","12  13031606                 1          10205        195        3573   \n","5   13031606                 1          30401        260        5193   \n","14  13031606                 1          30201        177        3144   \n","17  13031606                 1          80411        140        2700   \n","37  13031606                 1         140204         88        1413   \n","22  13031606                 1          30202        118        2190   \n","\n","    PERC_RECS  PERC_TOTAL  DIFFERENCE_PERC  \n","0        3.24        2.00             1.24  \n","6        2.86        1.85             1.01  \n","3        3.01        2.02             0.99  \n","4        3.00        2.03             0.97  \n","8        2.58        1.63             0.95  \n","9        2.54        1.64             0.89  \n","1        3.19        2.34             0.85  \n","10       2.50        1.67             0.83  \n","2        3.08        2.29             0.79  \n","7        2.75        1.98             0.77  \n","13       2.06        1.34             0.72  \n","16       1.99        1.32             0.68  \n","11       2.47        1.84             0.63  \n","15       1.99        1.41             0.58  \n","12       2.21        1.63             0.58  \n","5        2.94        2.37             0.57  \n","14       2.00        1.43             0.57  \n","17       1.58        1.23             0.35  \n","37       1.00        0.64             0.35  \n","22       1.34        1.00             0.34  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["customer.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPv7tlNcPABoDFliqaQGXet","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}
