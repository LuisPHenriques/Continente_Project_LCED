{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "171de7d2",
   "metadata": {},
   "source": [
    "# Data Import & Connection to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0ce1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luish\\anaconda3\\lib\\site-packages\\google\\auth\\_default.py:78: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from google.cloud import bigquery\n",
    "from itertools import product\n",
    "from functions import *\n",
    "\n",
    "# set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Set the float format to display numbers without scientific notation\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "# Set the client for future queries to BigQuery\n",
    "client = bigquery.Client(project = \"continente-lced-feup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9862be91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=Dr2IITnrICIQrJOOzN9Z7Hmj4bmhJR&access_type=offline&code_challenge=WAX8C2fRYBfGpW4cfLnvzIqFWjlOuAmgl704PtbszGc&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [C:\\Users\\luish\\AppData\\Roaming\\gcloud\\application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "WARNING: \n",
      "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b16e58",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "316f5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = client.query(\"\"\"\n",
    "   SELECT *\n",
    "   FROM \n",
    "       tables_raw.dim_customer \n",
    "       JOIN tables_raw.fact_transaction USING(CUSTOMER_ACCOUNT_NR_MASK)\n",
    "       JOIN tables_raw.dim_product USING(SKU)\n",
    "    WHERE \n",
    "        SUBCAT_CD_EXT IN (140304, 50401, 30301, 20201, 10301, 80103, 60102, 60401, 30401, 10101, 100102, 100204, 140204, \n",
    "        20302, 30201, 50203, 90201, 170101, 80404, 50402, 70202, 100201, 80409, 10303, 20306, 80411, 10102, 20305, 60105, 80110, \n",
    "        140301, 30202, 90202, 100101, 80105, 80104, 50202, 50303, 70204, 60306, 80403, 10302, 10201, 80405, 170304, 170303, 80406, \n",
    "        140201, 60302, 30403, 30304, 20204, 170106, 140205, 10204, 60404, 50301, 50302, 20205, 60406, 20301, 80407, 20203, 70201, 100205,\n",
    "        60106, 170302, 50201, 60301, 10205, 30203, 80401, 100202, 30302, 170111, 10202, 70203, 60303, 170109, 60403, 30402, 140302, 30208, 60307, \n",
    "        80107, 50403, 60103, 20307, 60305, 60101, 170307, 80414, 80415, 60405, 20303, 80402, 30204, 30206, 170310, 60304, 140206, 10203, 30205, 60107, \n",
    "        70206, 170108, 90203, 90204, 30207, 140303, 30303, 80408, 140202, 50304, 80101, 170313, 100203, 60402, 170305, 50305, 50404, 20202, 170110, \n",
    "        170105, 170112, 170301, 10206, 10208, 20304, 80102, 70205, 10207, 10305, 170309, 170114, 80111, 90206, 30306, 30305, 140203, 80413) \n",
    "        AND SEG_AGE_DSC = ']25;35]'\n",
    "        AND QTY >= 0\n",
    "    ORDER BY CUSTOMER_ACCOUNT_NR_MASK DESC, TIME_KEY ASC\n",
    "   \"\"\")\n",
    "\n",
    "df = query.result().to_dataframe() # Wait for the job to complete."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be7227ad",
   "metadata": {},
   "source": [
    "# Data Preparation (more to be done...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e64ae92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['LOC_BRAND_CD','PROD_DSCNT_ISSUED_AMT','NET_SLS_AMT','TRANS_DSCNT_RAT_AMT','DIRECT_DSCNT_AMT',\n",
    "                 'seg_lifestyle_dsc','SEG_AGE','SEG_AGE_DSC','seg_lifestage_dsc',\n",
    "                 'UNIT_BASE_DSC_EXT','SUBCAT_DSC_EXT','BIZ_UNIT_DSC_EXT','DEPARTMENT_DSC_EXT',\n",
    "                'PRODUCT_SHORT_DSC','BRAND_DSC','BRAND_TYPE_CD','CONVERSION_FACTOR','CAPACITY_UNIT','PRODUCT_DSC','SKU',\n",
    "                'LOCATION_CD','GROSS_SLS_AMT','CP4','CAT_DSC_EXT','PRODUCT_KEY','POS_TP_CD','PRICE_RANGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba3d06f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUSTOMER_ACCOUNT_NR_MASK         0\n",
       "GENDER                      207890\n",
       "FAMILY_MEMBERS              778011\n",
       "seg_lifestyle_cd                 0\n",
       "seg_lifestage_cd                 0\n",
       "TIME_KEY                         0\n",
       "TRANSACTION_ID_MASK              0\n",
       "POS_TP_CD                        0\n",
       "QTY                              0\n",
       "UNIT_BASE_CD_EXT                 0\n",
       "SUBCAT_CD_EXT                    0\n",
       "CAT_CD_EXT                       0\n",
       "BIZ_UNIT_CD_EXT                  0\n",
       "DEPARTMENT_CD_EXT                0\n",
       "PRICE_RANGE                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38d1321e",
   "metadata": {},
   "source": [
    "# Feature Engineering & ML Dataset Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3808f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'TIME_KEY' column to datetime format\n",
    "df['TIME_KEY'] = pd.to_datetime(df['TIME_KEY'], format='%Y%m%d')\n",
    "\n",
    "# create new columns for the day, week, day of the week, month, quarter, and year\n",
    "#df['DAY'] = df['TIME_KEY'].dt.day\n",
    "#df['WEEK'] = df['TIME_KEY'].dt.week\n",
    "#df['DOW'] = df['TIME_KEY'].dt.dayofweek\n",
    "df['MONTH'] = df['TIME_KEY'].dt.month\n",
    "df['QUARTER'] = df['TIME_KEY'].dt.quarter\n",
    "df['SEMESTER'] = df['MONTH'].apply(semester)\n",
    "df['YEAR'] = df['TIME_KEY'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dd3b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe by the customer's frequency score\n",
    "df = filter_customers(df)\n",
    "# Sort the dataframe (later suffled again)\n",
    "df = df.sort_values(['TIME_KEY','TRANSACTION_ID_MASK','YEAR','MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd0504cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique values of customer_id, category_id, month and year\n",
    "customer_ids = df['CUSTOMER_ACCOUNT_NR_MASK'].unique()\n",
    "category_ids = df['SUBCAT_CD_EXT'].unique()\n",
    "months = df['MONTH'].unique()\n",
    "years = df['YEAR'].unique()\n",
    "\n",
    "# create a new dataframe with all possible combinations of customer_id and category_id\n",
    "ml_dataset = pd.DataFrame(list(product(customer_ids, category_ids, months, years)), \n",
    "                                    columns=['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','MONTH','YEAR'])\n",
    "\n",
    "# add the quarter and semester columns based on the month value\n",
    "quarter_map = {1: 1, 2: 1, 3: 1, 4: 2, 5: 2, 6: 2, 7: 3, 8: 3, 9: 3, 10: 4, 11: 4, 12: 4}\n",
    "semester_map = {1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 2, 8: 2, 9: 2, 10: 2, 11: 2, 12: 2}\n",
    "\n",
    "ml_dataset['QUARTER'] = ml_dataset['MONTH'].map(quarter_map)\n",
    "ml_dataset['SEMESTER'] = ml_dataset['MONTH'].map(semester_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16745e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random sample of 1M rows to test the DM pipeline\n",
    "#ml_dataset = ml_dataset.sample(n=1000000)\n",
    "ml_dataset = ml_dataset.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','YEAR','MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28d88ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS\n",
    "\n",
    "df['CUST_NUM_TRANSACTIONS_MONTH'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR', 'MONTH'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['CUST_NUM_TRANSACTIONS_MONTH'] = df['CUST_NUM_TRANSACTIONS_MONTH'].astype(int)\n",
    "\n",
    "df['CUST_NUM_TRANSACTIONS_QUARTER'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR', 'QUARTER'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['CUST_NUM_TRANSACTIONS_QUARTER'] = df['CUST_NUM_TRANSACTIONS_QUARTER'].astype(int)\n",
    "\n",
    "df['CUST_NUM_TRANSACTIONS_SEMESTER'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR', 'SEMESTER'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['CUST_NUM_TRANSACTIONS_SEMESTER'] = df['CUST_NUM_TRANSACTIONS_SEMESTER'].astype(int)\n",
    "\n",
    "df['CUST_NUM_TRANSACTIONS_YEAR'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['CUST_NUM_TRANSACTIONS_YEAR'] = df['CUST_NUM_TRANSACTIONS_YEAR'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'MONTH', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'QUARTER', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'SEMESTER', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'YEAR', 'CUST_NUM_TRANSACTIONS', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67d73661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIQUE NUMBER OF SUBCATEGORIES BOUGHT\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_MONTH'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR', 'MONTH'])['SUBCAT_CD_EXT'].transform(count_unique)\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_MONTH'] = df['CUST_NUM_UNIQUE_SUBCAT_MONTH'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_QUARTER'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR', 'QUARTER'])['SUBCAT_CD_EXT'].transform(count_unique)\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_QUARTER'] = df['CUST_NUM_UNIQUE_SUBCAT_QUARTER'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_SEMESTER'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR', 'SEMESTER'])['SUBCAT_CD_EXT'].transform(count_unique)\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_SEMESTER'] = df['CUST_NUM_UNIQUE_SUBCAT_SEMESTER'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_YEAR'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR'])['SUBCAT_CD_EXT'].transform(count_unique)\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_YEAR'] = df['CUST_NUM_UNIQUE_SUBCAT_YEAR'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'MONTH', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'QUARTER', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'SEMESTER', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'YEAR', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f57279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE DAYS SINCE LAST CUSTOMER'S TRANSACTION\n",
    "\n",
    "df = calculate_rolling_avg(df, 'MONTH', 'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUST')\n",
    "df = calculate_rolling_avg(df, 'QUARTER', 'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUST')\n",
    "df = calculate_rolling_avg(df, 'SEMESTER', 'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUST')\n",
    "df = calculate_rolling_avg(df, 'YEAR', 'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUST')\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'MONTH', 'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'QUARTER', 'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'SEMESTER', 'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'YEAR', 'CUST_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUST', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb0f5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" ############ REVIEW LATER ############\\n# create an empty column for QTY in the new dataframe\\nml_dataset['QTY'] = 0\\n\\n# group the original dataframe by CUSTOMER_ACCOUNT_NR_MASK, SUBCAT_CD_EXT, and MONTH and calculate the sum of QTY\\ngrouped_df = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'SUBCAT_CD_EXT', 'MONTH', 'YEAR'])['QTY'].sum().reset_index()\\n\\nml_dataset = create_aggregations(df, ml_dataset, 'MONTH', 'CUST_NUM_UNIQUE_SUBCAT', False)\\nml_dataset = create_aggregations(df, ml_dataset, 'QUARTER', 'CUST_NUM_UNIQUE_SUBCAT', False)\\nml_dataset = create_aggregations(df, ml_dataset, 'SEMESTER', 'CUST_NUM_UNIQUE_SUBCAT', False)\\nml_dataset = create_aggregations(df, ml_dataset, 'YEAR', 'CUST_NUM_UNIQUE_SUBCAT', False)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' ############ REVIEW LATER ############\n",
    "# create an empty column for QTY in the new dataframe\n",
    "ml_dataset['QTY'] = 0\n",
    "\n",
    "# group the original dataframe by CUSTOMER_ACCOUNT_NR_MASK, SUBCAT_CD_EXT, and MONTH and calculate the sum of QTY\n",
    "grouped_df = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'SUBCAT_CD_EXT', 'MONTH', 'YEAR'])['QTY'].sum().reset_index()\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'MONTH', 'CUST_NUM_UNIQUE_SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'QUARTER', 'CUST_NUM_UNIQUE_SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'SEMESTER', 'CUST_NUM_UNIQUE_SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'YEAR', 'CUST_NUM_UNIQUE_SUBCAT', False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcbd0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE BASKET SIZE\n",
    "\n",
    "df['CUST_NUM_SUBCAT_MONTH'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR', 'MONTH'])['SUBCAT_CD_EXT'].transform(count)\n",
    "df['CUST_NUM_SUBCAT_MONTH'] = df['CUST_NUM_SUBCAT_MONTH']\n",
    "df['CUST_AVG_BASKET_SIZE_MONTH'] = df['CUST_NUM_SUBCAT_MONTH'] / df['CUST_NUM_TRANSACTIONS_MONTH']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_QUARTER'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR', 'QUARTER'])['SUBCAT_CD_EXT'].transform(count)\n",
    "df['CUST_NUM_SUBCAT_QUARTER'] = df['CUST_NUM_SUBCAT_QUARTER']\n",
    "df['CUST_AVG_BASKET_SIZE_QUARTER'] = df['CUST_NUM_SUBCAT_QUARTER'] / df['CUST_NUM_TRANSACTIONS_QUARTER']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_SEMESTER'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR', 'SEMESTER'])['SUBCAT_CD_EXT'].transform(count)\n",
    "df['CUST_NUM_SUBCAT_SEMESTER'] = df['CUST_NUM_SUBCAT_SEMESTER']\n",
    "df['CUST_AVG_BASKET_SIZE_SEMESTER'] = df['CUST_NUM_SUBCAT_SEMESTER'] / df['CUST_NUM_TRANSACTIONS_SEMESTER']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_YEAR'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'YEAR'])['SUBCAT_CD_EXT'].transform(count)\n",
    "df['CUST_NUM_SUBCAT_YEAR'] = df['CUST_NUM_SUBCAT_YEAR']\n",
    "df['CUST_AVG_BASKET_SIZE_YEAR'] = df['CUST_NUM_SUBCAT_YEAR'] / df['CUST_NUM_TRANSACTIONS_YEAR']\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'MONTH', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'QUARTER', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'SEMESTER', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'YEAR', 'CUST_AVG_BASKET_SIZE', 'CUST', True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4087154b",
   "metadata": {},
   "source": [
    "Subcategory features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14aa99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS\n",
    "\n",
    "df['SUBCAT_NUM_TRANSACTIONS_MONTH'] = df.groupby(['SUBCAT_CD_EXT', 'YEAR', 'MONTH'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['SUBCAT_NUM_TRANSACTIONS_MONTH'] = df['SUBCAT_NUM_TRANSACTIONS_MONTH'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_TRANSACTIONS_QUARTER'] = df.groupby(['SUBCAT_CD_EXT', 'YEAR', 'QUARTER'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['SUBCAT_NUM_TRANSACTIONS_QUARTER'] = df['SUBCAT_NUM_TRANSACTIONS_QUARTER'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_TRANSACTIONS_SEMESTER'] = df.groupby(['SUBCAT_CD_EXT', 'YEAR', 'SEMESTER'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['SUBCAT_NUM_TRANSACTIONS_SEMESTER'] = df['SUBCAT_NUM_TRANSACTIONS_SEMESTER'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_TRANSACTIONS_YEAR'] = df.groupby(['SUBCAT_CD_EXT', 'YEAR'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['SUBCAT_NUM_TRANSACTIONS_YEAR'] = df['SUBCAT_NUM_TRANSACTIONS_YEAR'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'MONTH', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'QUARTER', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'SEMESTER', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'YEAR', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a3648ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIQUE NUMBER OF CUSTOMERS WHO BOUGHT FROM A SUBCATEGORY\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_MONTH'] = df.groupby(['SUBCAT_CD_EXT', 'YEAR', 'MONTH'])['CUSTOMER_ACCOUNT_NR_MASK'].transform(count_unique)\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_MONTH'] = df['SUBCAT_NUM_UNIQUE_CUST_MONTH'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_QUARTER'] = df.groupby(['SUBCAT_CD_EXT', 'YEAR', 'QUARTER'])['CUSTOMER_ACCOUNT_NR_MASK'].transform(count_unique)\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_QUARTER'] = df['SUBCAT_NUM_UNIQUE_CUST_QUARTER'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_SEMESTER'] = df.groupby(['SUBCAT_CD_EXT', 'YEAR', 'SEMESTER'])['CUSTOMER_ACCOUNT_NR_MASK'].transform(count_unique)\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_SEMESTER'] = df['SUBCAT_NUM_UNIQUE_CUST_SEMESTER'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_YEAR'] = df.groupby(['SUBCAT_CD_EXT', 'YEAR'])['CUSTOMER_ACCOUNT_NR_MASK'].transform(count_unique)\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_YEAR'] = df['SUBCAT_NUM_UNIQUE_CUST_YEAR'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'MONTH', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'QUARTER', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'SEMESTER', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'YEAR', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b98bce3a",
   "metadata": {},
   "source": [
    "Customer-Subcategory features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4345f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS FOR A SUBCATEGORY BY A SPECIFIC CUSTOMER\n",
    "\n",
    "df['CUSTSUBCAT_NUM_TRANSACTIONS_MONTH'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'SUBCAT_CD_EXT', 'YEAR', 'MONTH'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['CUSTSUBCAT_NUM_TRANSACTIONS_MONTH'] = df['CUSTSUBCAT_NUM_TRANSACTIONS_MONTH'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_NUM_TRANSACTIONS_QUARTER'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'SUBCAT_CD_EXT', 'YEAR', 'QUARTER'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['CUSTSUBCAT_NUM_TRANSACTIONS_QUARTER'] = df['CUSTSUBCAT_NUM_TRANSACTIONS_QUARTER'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_NUM_TRANSACTIONS_SEMESTER'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'SUBCAT_CD_EXT', 'YEAR', 'SEMESTER'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['CUSTSUBCAT_NUM_TRANSACTIONS_SEMESTER'] = df['CUSTSUBCAT_NUM_TRANSACTIONS_SEMESTER'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_NUM_TRANSACTIONS_YEAR'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'SUBCAT_CD_EXT', 'YEAR'])['TRANSACTION_ID_MASK'].transform(count_unique_transactions)\n",
    "df['CUSTSUBCAT_NUM_TRANSACTIONS_YEAR'] = df['CUSTSUBCAT_NUM_TRANSACTIONS_YEAR'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'MONTH', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'QUARTER', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'SEMESTER', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'YEAR', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d380e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE DAYS SINCE LAST CUSTOMER'S TRANSACTION\n",
    "\n",
    "df = calculate_rolling_avg(df, 'MONTH', 'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUSTSUBCAT')\n",
    "df = calculate_rolling_avg(df, 'QUARTER', 'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUSTSUBCAT')\n",
    "df = calculate_rolling_avg(df, 'SEMESTER', 'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUSTSUBCAT')\n",
    "df = calculate_rolling_avg(df, 'YEAR', 'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUSTSUBCAT')\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'MONTH', 'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUSTSUBCAT', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'QUARTER', 'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUSTSUBCAT', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'SEMESTER', 'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUSTSUBCAT', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, 'YEAR', 'CUSTSUBCAT_AVG_DAYS_SINCE_PRIOR_TRANSACTION', 'CUSTSUBCAT', True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5affcba2",
   "metadata": {},
   "source": [
    "Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3045e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = fill_missing_values(df)  # Fills the missing values of the customer column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6578e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "customer_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['GENDER']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['GENDER'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(customer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c25de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "family_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['FAMILY_MEMBERS']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['FAMILY_MEMBERS'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(family_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e904447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestyle_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['seg_lifestyle_cd']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['SEG_LIFESTYLE_CD'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(lifestyle_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22e1e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestage_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['seg_lifestage_cd']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['SEG_LIFESTAGE_CD'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(lifestage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da9c09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = client.query(\"\"\"\n",
    "   SELECT SUBCAT_CD_EXT, CAT_CD_EXT, PRICE_RANGE\n",
    "   FROM tables_raw.dim_product\n",
    "   \"\"\")\n",
    "\n",
    "products = query.result().to_dataframe() # Wait for the job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89950622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestage_dict = dict(zip(products['SUBCAT_CD_EXT'], products['CAT_CD_EXT']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['CAT_CD_EXT'] = ml_dataset['SUBCAT_CD_EXT'].map(lifestage_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffe6eeb2",
   "metadata": {},
   "source": [
    "Target features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d837c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dataset = ml_dataset.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','YEAR','MONTH'])\n",
    "ml_dataset = compute_target(ml_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85f5f290",
   "metadata": {},
   "source": [
    "# Load dataset into BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6be2e32c",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.43 GiB for an array with shape (9, 21278592) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Shuffle the dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ml_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mml_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5447\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[0;32m   5444\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m   5446\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39msample(obj_len, size, replace, weights, rs)\n\u001b[1;32m-> 5447\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[0;32m   5450\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3703\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3699\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_take((), kwargs)\n\u001b[0;32m   3701\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m-> 3703\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   3705\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:900\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    897\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    899\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:692\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    685\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    686\u001b[0m         indexer,\n\u001b[0;32m    687\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    688\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    689\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    690\u001b[0m     )\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 692\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    693\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    694\u001b[0m             indexer,\n\u001b[0;32m    695\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    696\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    697\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    698\u001b[0m             ),\n\u001b[0;32m    699\u001b[0m         )\n\u001b[0;32m    700\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    701\u001b[0m     ]\n\u001b[0;32m    703\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    704\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:693\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    685\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    686\u001b[0m         indexer,\n\u001b[0;32m    687\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    688\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    689\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    690\u001b[0m     )\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    692\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 693\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    701\u001b[0m     ]\n\u001b[0;32m    703\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    704\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1137\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;66;03m#  this assertion\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m new_mgr_locs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:158\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    156\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    161\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.43 GiB for an array with shape (9, 21278592) and data type int64"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataframe\n",
    "ml_dataset = ml_dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b07ba597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=continente-lced-feup, location=europe-southwest1, id=dca1c420-968d-41cf-ad6d-284d50cfa12e>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### SAVE DATAFRAME TO BIGQUERY ####\n",
    "client.load_table_from_dataframe(ml_dataset, 'tables_staging.df_models').result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
