{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "171de7d2",
   "metadata": {},
   "source": [
    "# Data Import & Connection to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0ce1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from google.cloud import bigquery\n",
    "from itertools import product\n",
    "from functions import *\n",
    "\n",
    "# set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Set the float format to display numbers without scientific notation\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "# Set the client for future queries to BigQuery\n",
    "client = bigquery.Client(project = \"continente-lced-feup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9862be91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=AWTa2mRCHRoWD9pa2WBFv2EkA21pGj&access_type=offline&code_challenge=UwUBDeKjruOFY5mhylt8h5WZSn5pwy4E8eSEDiQ8IGY&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [/Users/vp/.config/gcloud/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"continente-lced-feup\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b16e58",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "316f5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = client.query(\"\"\"\n",
    "   SELECT *\n",
    "   FROM \n",
    "       tables_raw.dim_customer \n",
    "       JOIN tables_raw.fact_transaction USING(CUSTOMER_ACCOUNT_NR_MASK)\n",
    "       JOIN tables_raw.dim_product USING(SKU)\n",
    "    WHERE \n",
    "        SUBCAT_CD_EXT IN (140304, 50401, 30301, 20201, 10301, 80103, 60102, 60401, 30401, 10101, 100102, 100204, 140204, \n",
    "        20302, 30201, 50203, 90201, 170101, 80404, 50402, 70202, 100201, 80409, 10303, 20306, 80411, 10102, 20305, 60105, 80110, \n",
    "        140301, 30202, 90202, 100101, 80105, 80104, 50202, 50303, 70204, 60306, 80403, 10302, 10201, 80405, 170304, 170303, 80406, \n",
    "        140201, 60302, 30403, 30304, 20204, 170106, 140205, 10204, 60404, 50301, 50302, 20205, 60406, 20301, 80407, 20203, 70201, 100205,\n",
    "        60106, 170302, 50201, 60301, 10205, 30203, 80401, 100202, 30302, 170111, 10202, 70203, 60303, 170109, 60403, 30402, 140302, 30208, 60307, \n",
    "        80107, 50403, 60103, 20307, 60305, 60101, 170307, 80414, 80415, 60405, 20303, 80402, 30204, 30206, 170310, 60304, 140206, 10203, 30205, 60107, \n",
    "        70206, 170108, 90203, 90204, 30207, 140303, 30303, 80408, 140202, 50304, 80101, 170313, 100203, 60402, 170305, 50305, 50404, 20202, 170110, \n",
    "        170105, 170112, 170301, 10206, 10208, 20304, 80102, 70205, 10207, 10305, 170309, 170114, 80111, 90206, 30306, 30305, 140203, 80413) \n",
    "        AND SEG_AGE_DSC = ']25;35]'\n",
    "        AND QTY >= 0\n",
    "    ORDER BY CUSTOMER_ACCOUNT_NR_MASK DESC, TIME_KEY ASC\n",
    "   \"\"\")\n",
    "\n",
    "df = query.result().to_dataframe() # Wait for the job to complete."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be7227ad",
   "metadata": {},
   "source": [
    "# Data Preparation (more to be done...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e64ae92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['LOC_BRAND_CD','PROD_DSCNT_ISSUED_AMT','NET_SLS_AMT','TRANS_DSCNT_RAT_AMT','DIRECT_DSCNT_AMT',\n",
    "                 'seg_lifestyle_dsc','SEG_AGE','SEG_AGE_DSC','seg_lifestage_dsc',\n",
    "                 'UNIT_BASE_DSC_EXT','SUBCAT_DSC_EXT','BIZ_UNIT_DSC_EXT','DEPARTMENT_DSC_EXT',\n",
    "                'PRODUCT_SHORT_DSC','BRAND_DSC','BRAND_TYPE_CD','CONVERSION_FACTOR','CAPACITY_UNIT','PRODUCT_DSC','SKU',\n",
    "                'LOCATION_CD','GROSS_SLS_AMT','CP4','CAT_DSC_EXT','PRODUCT_KEY','POS_TP_CD','PRICE_RANGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d06f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUSTOMER_ACCOUNT_NR_MASK         0\n",
       "GENDER                      207890\n",
       "FAMILY_MEMBERS              778011\n",
       "seg_lifestyle_cd                 0\n",
       "seg_lifestage_cd                 0\n",
       "TIME_KEY                         0\n",
       "TRANSACTION_ID_MASK              0\n",
       "QTY                              0\n",
       "UNIT_BASE_CD_EXT                 0\n",
       "SUBCAT_CD_EXT                    0\n",
       "CAT_CD_EXT                       0\n",
       "BIZ_UNIT_CD_EXT                  0\n",
       "DEPARTMENT_CD_EXT                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38d1321e",
   "metadata": {},
   "source": [
    "# Feature Engineering & ML Dataset Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3808f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'TIME_KEY' column to datetime format\n",
    "df['TIME_KEY'] = pd.to_datetime(df['TIME_KEY'], format='%Y%m%d')\n",
    "\n",
    "# create new columns for the day, week, day of the week, month, quarter, and year\n",
    "#df['DAY'] = df['TIME_KEY'].dt.day\n",
    "#df['WEEK'] = df['TIME_KEY'].dt.week\n",
    "#df['DOW'] = df['TIME_KEY'].dt.dayofweek\n",
    "df['MONTH'] = df['TIME_KEY'].dt.month\n",
    "df['QUARTER'] = df['TIME_KEY'].dt.quarter\n",
    "df['SEMESTER'] = df['MONTH'].apply(semester)\n",
    "df['YEAR'] = df['TIME_KEY'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd3b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe by the customer's frequency score\n",
    "df = filter_customers(df)\n",
    "# Sort the dataframe (later suffled again)\n",
    "df = df.sort_values(['TIME_KEY','TRANSACTION_ID_MASK','YEAR','MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779ad40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Drop duplicates, keeping only the first occurrence of each customer ID\n",
    "df_first_transaction = df.drop_duplicates('CUSTOMER_ACCOUNT_NR_MASK', keep='first')\n",
    "\n",
    "# Step 3: Create a new DataFrame with customer ID and first transaction date\n",
    "df_first_transaction = df_first_transaction[['CUSTOMER_ACCOUNT_NR_MASK', 'TIME_KEY']]\n",
    "\n",
    "# Convert the 'TIME_KEY' column to datetime type\n",
    "df_first_transaction['TIME_KEY'] = pd.to_datetime(df_first_transaction['TIME_KEY'])\n",
    "\n",
    "# Extract the year and month from the 'TIME_KEY' column and format it as \"year-month\"\n",
    "df_first_transaction['TIME_KEY'] = df_first_transaction['TIME_KEY'].dt.strftime('%Y-%m')\n",
    "\n",
    "df_first_transaction = df_first_transaction.sort_values(['CUSTOMER_ACCOUNT_NR_MASK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd0504cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique values of customer_id, category_id, month and year\n",
    "customer_ids = df['CUSTOMER_ACCOUNT_NR_MASK'].unique()\n",
    "category_ids = df['SUBCAT_CD_EXT'].unique()\n",
    "months = df['MONTH'].unique()\n",
    "years = df['YEAR'].unique()\n",
    "\n",
    "# create a new dataframe with all possible combinations of customer_id and category_id\n",
    "ml_dataset = pd.DataFrame(list(product(customer_ids, category_ids, months, years)), \n",
    "                                    columns=['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','MONTH','YEAR'])\n",
    "\n",
    "# add the quarter and semester columns based on the month value\n",
    "quarter_map = {1: 1, 2: 1, 3: 1, 4: 2, 5: 2, 6: 2, 7: 3, 8: 3, 9: 3, 10: 4, 11: 4, 12: 4}\n",
    "semester_map = {1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 2, 8: 2, 9: 2, 10: 2, 11: 2, 12: 2}\n",
    "\n",
    "ml_dataset['QUARTER'] = ml_dataset['MONTH'].map(quarter_map)\n",
    "ml_dataset['SEMESTER'] = ml_dataset['MONTH'].map(semester_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d930de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 'year' and 'month' columns into a single column\n",
    "ml_dataset['TIME_KEY_agg'] = ml_dataset['YEAR'].astype(str) + '-' + ml_dataset['MONTH'].astype(str)\n",
    "\n",
    "# Convert the 'TIME_KEY' column to datetime format\n",
    "ml_dataset['TIME_KEY_agg'] = pd.to_datetime(ml_dataset['TIME_KEY_agg'], format='%Y-%m')\n",
    "\n",
    "# Extract the year and month from the 'TIME_KEY' column and format it as \"year-month\"\n",
    "ml_dataset['TIME_KEY_agg'] = ml_dataset['TIME_KEY_agg'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Step 3: Merge with the aggregated dataset\n",
    "ml_dataset = pd.merge(ml_dataset, df_first_transaction, on='CUSTOMER_ACCOUNT_NR_MASK', how='left')\n",
    "\n",
    "# Step 4: Filter the aggregated dataset based on the first transaction date\n",
    "ml_dataset = ml_dataset[ml_dataset['TIME_KEY_agg'] >= ml_dataset['TIME_KEY']]\n",
    "\n",
    "ml_dataset = ml_dataset.drop(columns=['TIME_KEY_agg','TIME_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6523fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dataset = ml_dataset.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','YEAR','MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0d0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','TIME_KEY'])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d88ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS - CORRETO!\n",
    "\n",
    "df_uniques = df.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='first').reset_index()\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_30_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='30D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_90_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='90D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_180_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='180D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUST_NUM_TRANSACTIONS_360_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='360D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df = pd.merge(df, df_uniques[['TRANSACTION_ID_MASK','CUST_NUM_TRANSACTIONS_30_DAYS','CUST_NUM_TRANSACTIONS_90_DAYS','CUST_NUM_TRANSACTIONS_180_DAYS',\n",
    "                             'CUST_NUM_TRANSACTIONS_360_DAYS']], on=['TRANSACTION_ID_MASK'], how='left')\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUST_NUM_TRANSACTIONS', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "600002d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL QUATITY BOUGHT BY CUSTOMER - CORRETO!\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_30_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='30D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_90_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='90D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_180_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='180D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUST_TOTAL_QTY_BOUGHT_360_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='360D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUST_TOTAL_QTY_BOUGHT', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d73661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIQUE NUMBER OF SUBCATEGORIES BOUGHT - CORRETO!\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_30_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='30D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_90_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='90D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_180_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='180D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "df['CUST_NUM_UNIQUE_SUBCAT_360_DAYS'] = df.groupby('CUSTOMER_ACCOUNT_NR_MASK').rolling(window='360D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                        .apply(lambda x: x.nunique()).reset_index()['SUBCAT_CD_EXT'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUST_NUM_UNIQUE_SUBCAT', 'CUST', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f57279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE DAYS FOR NEXT CUSTOMER'S TRANSACTION - CORRETO!\n",
    "\n",
    "df_uniques = df.copy()\n",
    "df_uniques['DAYS_FOR_NEXT_TRANSACTION'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK'])['TIME_KEY'].diff(-1).dt.days \\\n",
    "                                              .fillna(0).apply(lambda x: abs(x))\n",
    "df_uniques = df_uniques.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='last').reset_index()\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                   .rolling(window='30D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(30)\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_90_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                   .rolling(window='90D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(60)\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_180_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                    .rolling(window='180D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(180)\n",
    "\n",
    "df_uniques['CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_360_DAYS'] = df_uniques.groupby('CUSTOMER_ACCOUNT_NR_MASK') \\\n",
    "                                                                    .rolling(window='360D', on='TIME_KEY', min_periods=1).DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(360)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUST_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUST', False)\n",
    "\n",
    "# Regression Feature - Average days for the next transaction in the next 30 days of a certain month, by customer\n",
    "\n",
    "ml_dataset['REG_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS'] = ml_dataset.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                    .CUST_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS \\\n",
    "                                                                    .shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcbd0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE BASKET SIZE - CORRETO!\n",
    "\n",
    "df['CUST_NUM_SUBCAT_30_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='30D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_30_DAYS'] = df['CUST_NUM_SUBCAT_30_DAYS'] / df['CUST_NUM_TRANSACTIONS_30_DAYS']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_90_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='90D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_90_DAYS'] = df['CUST_NUM_SUBCAT_90_DAYS'] / df['CUST_NUM_TRANSACTIONS_90_DAYS']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_180_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='180D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_180_DAYS'] = df['CUST_NUM_SUBCAT_180_DAYS'] / df['CUST_NUM_TRANSACTIONS_180_DAYS']\n",
    "\n",
    "df['CUST_NUM_SUBCAT_360_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK']) \\\n",
    "                                  .rolling(window='360D', on='TIME_KEY', min_periods=1).SUBCAT_CD_EXT \\\n",
    "                                  .count().reset_index()['SUBCAT_CD_EXT']\n",
    "df['CUST_AVG_BASKET_SIZE_360_DAYS'] = df['CUST_NUM_SUBCAT_360_DAYS'] / df['CUST_NUM_TRANSACTIONS_360_DAYS']\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUST_AVG_BASKET_SIZE', 'CUST', True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4087154b",
   "metadata": {},
   "source": [
    "Subcategory features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ed446ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['SUBCAT_CD_EXT','TIME_KEY'])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14aa99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS - CORRETO!\n",
    "\n",
    "df_uniques = df.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='first').reset_index()\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_30_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='30D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_90_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='90D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_180_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='180D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['SUBCAT_NUM_TRANSACTIONS_360_DAYS'] = df_uniques.groupby('SUBCAT_CD_EXT').rolling(window='360D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'SUBCAT_NUM_TRANSACTIONS', 'SUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7328026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL QUATITY BOUGHT BY SUBCATEGORY - CORRETO!\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_30_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='30D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_90_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='90D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_180_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='180D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['SUBCAT_TOTAL_QTY_BOUGHT_360_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='360D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                        .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'SUBCAT_TOTAL_QTY_BOUGHT', 'SUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a3648ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIQUE NUMBER OF CUSTOMERS WHO BOUGHT FROM A SUBCATEGORY - CORRETO!\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_30_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='30D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_90_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='90D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_180_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='180D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "df['SUBCAT_NUM_UNIQUE_CUST_360_DAYS'] = df.groupby('SUBCAT_CD_EXT').rolling(window='360D', on='TIME_KEY', min_periods=1).CUSTOMER_ACCOUNT_NR_MASK \\\n",
    "                                         .apply(lambda x: x.nunique()).reset_index()['CUSTOMER_ACCOUNT_NR_MASK'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'SUBCAT_NUM_UNIQUE_CUST', 'SUBCAT', False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b98bce3a",
   "metadata": {},
   "source": [
    "Customer-Subcategory features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "848079f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','TIME_KEY'])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4345f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF ORDERS FOR A SUBCATEGORY BY A SPECIFIC CUSTOMER - CORRETO!\n",
    "\n",
    "df_uniques = df.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='first').reset_index()\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_30_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='30D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_90_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='90D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                        .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_180_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='180D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_NUM_TRANSACTIONS_360_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='360D', on='TIME_KEY', min_periods=1).TRANSACTION_ID_MASK \\\n",
    "                                                         .count().reset_index()['TRANSACTION_ID_MASK'].astype(int)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUSTSUBCAT_NUM_TRANSACTIONS', 'CUSTSUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "875e4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL QUATITY BOUGHT BY CUSTOMER BY SUBCATEGORY - CORRETO!\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_30_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='30D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                              .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_90_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='90D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                              .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_180_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='180D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                               .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "df['CUSTSUBCAT_TOTAL_QTY_BOUGHT_360_DAYS'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']).rolling(window='360D', on='TIME_KEY', min_periods=1).QTY \\\n",
    "                                               .sum().reset_index()['QTY'].astype(int)\n",
    "\n",
    "\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '30_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '90_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '180_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df, ml_dataset, '360_DAYS', 'CUSTSUBCAT_TOTAL_QTY_BOUGHT', 'CUSTSUBCAT', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d380e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE DAYS FOR NEXT CUSTOMER'S TRANSACTION WITH A CERTAIN SUBCATEGORY - CORRETO!\n",
    "\n",
    "df_uniques = df.copy()\n",
    "df_uniques['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] = df.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT'])['TIME_KEY'].diff(-1).dt.days \\\n",
    "                                              .fillna(0).apply(lambda x: abs(x))\n",
    "df_uniques = df_uniques.drop_duplicates(subset='TRANSACTION_ID_MASK', keep='last').reset_index()\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_30_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                   .rolling(window='30D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(30)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_90_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                   .rolling(window='90D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                   .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                   .fillna(60)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_180_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                    .rolling(window='180D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(180)\n",
    "\n",
    "df_uniques['CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION_360_DAYS'] = df_uniques.groupby(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT']) \\\n",
    "                                                                    .rolling(window='360D', on='TIME_KEY', min_periods=1).CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION \\\n",
    "                                                                    .apply(lambda x: x[:-1].mean()).reset_index()['CUSTSUBCAT_DAYS_FOR_NEXT_TRANSACTION'] \\\n",
    "                                                                    .fillna(360)\n",
    "\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '30_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '90_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '180_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)\n",
    "ml_dataset = create_aggregations(df_uniques, ml_dataset, '360_DAYS', 'CUSTSUBCAT_AVG_DAYS_FOR_NEXT_TRANSACTION', 'CUSTSUBCAT', False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5affcba2",
   "metadata": {},
   "source": [
    "Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3045e6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/41/p5vf899j42g1p4zhnsdw68d40000gn/T/ipykernel_31299/2594719012.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcustomer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_missing_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Fills the missing values of the customer column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/MDSE/2S/LCED/Continente_Project_LCED/functions.py\u001b[0m in \u001b[0;36mfill_missing_values\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# Predict the missing values in the 'GENDER' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GENDER'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mpredicted_gender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;31m# Assign the predicted values back to the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;31m# the weighting so we do not compute them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    822\u001b[0m         )\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             results = ArgKmin.compute(\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \"\"\"\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             return ArgKmin64.compute(\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36mthreadpool_limits\u001b[0;34m(limits, user_api)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreadpool_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, limits, user_api)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_threadpool_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_set_threadpool_limits\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         modules = _ThreadpoolInfo(prefixes=self._prefixes,\n\u001b[0m\u001b[1;32m    269\u001b[0m                                   user_api=self._user_api)\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_if_incompatible_openmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_load_modules\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;34m\"\"\"Loop through loaded libraries and store supported ones\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"darwin\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_modules_with_dyld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"win32\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_find_modules_with_dyld\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Store the module if it is supported and selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_module_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_make_module_from_path\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefixes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0muser_api\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0mmodule_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_RTLD_NOLOAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_extra_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36mget_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    644\u001b[0m                              lambda: None)\n\u001b[1;32m    645\u001b[0m         \u001b[0mget_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"OpenBLAS\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "customer = fill_missing_values(df)  # Fills the missing values of the customer column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6578e52b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'customer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/41/p5vf899j42g1p4zhnsdw68d40000gn/T/ipykernel_31299/1250903796.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcustomer_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUSTOMER_ACCOUNT_NR_MASK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GENDER'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mml_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GENDER'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUSTOMER_ACCOUNT_NR_MASK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'customer' is not defined"
     ]
    }
   ],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "customer_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['GENDER']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['GENDER'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(customer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "family_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['FAMILY_MEMBERS']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['FAMILY_MEMBERS'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(family_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e904447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestyle_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['seg_lifestyle_cd']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['SEG_LIFESTYLE_CD'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(lifestyle_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestage_dict = dict(zip(customer['CUSTOMER_ACCOUNT_NR_MASK'], customer['seg_lifestage_cd']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['SEG_LIFESTAGE_CD'] = ml_dataset['CUSTOMER_ACCOUNT_NR_MASK'].map(lifestage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da9c09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = client.query(\"\"\"\n",
    "   SELECT SUBCAT_CD_EXT, CAT_CD_EXT, PRICE_RANGE\n",
    "   FROM tables_raw.dim_product\n",
    "   \"\"\")\n",
    "\n",
    "products = query.result().to_dataframe() # Wait for the job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89950622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps CUSTOMER_ACCOUNT_NR_MASK values to their corresponding gender values\n",
    "lifestage_dict = dict(zip(products['SUBCAT_CD_EXT'], products['CAT_CD_EXT']))\n",
    "\n",
    "# map the gender values to the CUSTOMER_ACCOUNT_NR_MASK column in result_df using the customer_dict mapping\n",
    "ml_dataset['CAT_CD_EXT'] = ml_dataset['SUBCAT_CD_EXT'].map(lifestage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01e9fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_target_2(df_ml):\n",
    "    # create a new column 'BOUGHT_SUBCAT' that indicates if a customer bought a subcategory in a given month\n",
    "    df_ml['TARGET'] = (df_ml['CUSTSUBCAT_NUM_TRANSACTIONS_30_DAYS'] > 0).astype(int)\n",
    "    \n",
    "    # group the dataframe by customer_id and category_id\n",
    "    grouped = df_ml.groupby(['CUSTOMER_ACCOUNT_NR_MASK', 'SUBCAT_CD_EXT'])\n",
    "\n",
    "    # create a new column 'PREV_BOUGHT_SUBCAT' that has the value of 'BOUGHT_SUBCAT' shifted by one month\n",
    "    df_ml['TARGET'] = grouped['TARGET'].shift(-1).fillna(2)\n",
    "    df_ml['TARGET'] = df_ml['TARGET'].astype(int)\n",
    "    df_ml['TARGET'] = df_ml['TARGET'].replace(2, None)\n",
    "    \n",
    "    return df_ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffe6eeb2",
   "metadata": {},
   "source": [
    "Target features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d837c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dataset = ml_dataset.sort_values(['CUSTOMER_ACCOUNT_NR_MASK','SUBCAT_CD_EXT','YEAR','MONTH'])\n",
    "ml_dataset = compute_target_2(ml_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85f5f290",
   "metadata": {},
   "source": [
    "# Load dataset into BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6ee6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataframe\n",
    "ml_dataset = ml_dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b07ba597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=continente-lced-feup, location=europe-southwest1, id=09459174-0ea1-4927-b301-3d9453e27c04>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### SAVE DATAFRAME TO BIGQUERY ####\n",
    "client.load_table_from_dataframe(ml_dataset, 'tables_staging.df_models').result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
